{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python DAME-FLAME package used to analyze STAR Dataset\n",
    "\n",
    "Here we demonstrate an experimental use-case for the DAME algorithm on the Tennessee’s\n",
    "Student Teachers Achievement Ratio (STAR) Dataset. This dataset originates from an experiment\n",
    "beginning in 1985, in which elementary school students and their teachers across 79\n",
    "schools in Tennessee were randomly assigned to classes of small or regular sizes from Kindergarten\n",
    "through 3rd grade (Achilles, Bain, Bellott, Boyd-Zaharias, Finn, Folger, Johnston,\n",
    "and Word 2008). Although data is available for students not participating in the experiment,\n",
    "we limit to the experimental dataset in which treatment was random. The results showed\n",
    "that a small class size attendance leads to higher standardized test performance, and long\n",
    "term benefits in increased college entrance exam taking, especially among minority students\n",
    "(Krueger and Whitmore 2001).\n",
    "\n",
    "### 1. Clean Dataset\n",
    "Our cleaned dataset has around 5000 students with reading scores ranging from 315 to 627.\n",
    "Our covariates include children’s characteristics, teacher’s characteristics and school characteristics.\n",
    "The children’s characteristics are gender, race (binary, with White and Asian in one\n",
    "group, and all other races in the other group), free lunch status, and age in months (binned\n",
    "into deciles). The teacher characteristics include race, gender, and having a higher degree\n",
    "than bachelors. The school characteristics are urbanicity (rural, urban, suburban, and inner\n",
    "city) and a school identification number, with one for each of the 79 schools.\n",
    "\n",
    "Please download the data here: https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl:1902.1/10766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neha\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import dame_flame\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import heapq\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAR_Students = pd.read_spss('STAR_Students.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trunc = STAR_Students.loc[:, STAR_Students.columns.intersection(\n",
    "    ['gkclasstype', 'gender', 'race', 'gkfreelunch', 'gkschid', 'gktmathss', 'gktreadss', 'g1freelunch', 'g2freelunch', 'g3freelunch',\n",
    "    'gktgen', 'gktrace', 'gkthighdegree', 'birthmonth', 'birthyear', 'gksurban'])]\n",
    "\n",
    "\n",
    "d = {\"WHITE\": 1, \"BLACK\": 0, \"ASIAN\": 1, \"HISPANIC\": 0, \"OTHER\": 0, \n",
    "     \"NATIVE AMERICAN\": 0}\n",
    "df_trunc['race'] = df_trunc['race'].map(d)\n",
    "\n",
    "d = {\"NON-FREE LUNCH\": 0, \"FREE LUNCH\": 1}\n",
    "df_trunc['gkfreelunch'] = df_trunc['gkfreelunch'].map(d)\n",
    "df_trunc['g1freelunch'] = df_trunc['g1freelunch'].map(d)\n",
    "df_trunc['g2freelunch'] = df_trunc['g2freelunch'].map(d)\n",
    "df_trunc['g3freelunch'] = df_trunc['g3freelunch'].map(d)\n",
    "\n",
    "d = {\"BACHELORS\": 0, \"MASTERS\": 1, \"MASTERS + \": 1, \"SPECIALIST\": 1}\n",
    "df_trunc['gkthighdegree'] = df_trunc['gkthighdegree'].map(d)\n",
    "\n",
    "d = {\"MALE\": 1, \"FEMALE\": 0}\n",
    "df_trunc['gender'] = df_trunc['gender'].map(d)\n",
    "df_trunc['gktgen'] = df_trunc['gktgen'].map(d)\n",
    "\n",
    "d = {\"WHITE\": 1, \"BLACK\": 0}\n",
    "df_trunc['gktrace'] = df_trunc['gktrace'].map(d)\n",
    "\n",
    "d = {\"JANUARY\": 0, \"FEBRUARY\": 1, \"MARCH\": 2, \"APRIL\": 3, \"MAY\": 4, \n",
    "     \"JUNE\": 5, \"JULY\": 6, \"AUGUST\": 7, \"SEPTEMBER\": 8, \"OCTOBER\": 9, \n",
    "     \"NOVEMBER\": 10, \"DECEMBER\": 11}\n",
    "df_trunc['birthmonth'] = df_trunc['birthmonth'].map(d)\n",
    "\n",
    "d = {1977: 0, 1978: 1, 1979: 2, 1980:3, 1981:4}\n",
    "df_trunc['birthyear'] = df_trunc['birthyear'].map(d)\n",
    "\n",
    "d = {\"RURAL\": 0, \"URBAN\":1, \"SUBURBAN\": 2, \"INNER CITY\": 3}\n",
    "df_trunc['gksurban'] = df_trunc['gksurban'].map(d)\n",
    "\n",
    "d = {\"SMALL CLASS\": int(1), \"REGULAR CLASS\": int(0), \n",
    "     \"REGULAR + AIDE CLASS\": int(0)}\n",
    "df_trunc['ksmall'] = df_trunc['gkclasstype'].map(d)\n",
    "\n",
    "# Create age variable counting months\n",
    "df_trunc['age'] = df_trunc['birthyear']*12 + df_trunc['birthmonth']\n",
    "# Bin age into deciles\n",
    "df_trunc['age'] = pd.qcut(df_trunc['age'], q=10, labels=False)\n",
    "df_trunc = df_trunc.drop(columns=['gkclasstype', 'birthmonth', 'birthyear'])\n",
    "df_trunc = df_trunc.rename(columns={\"ksmall\": \"treated\"}) ## NOTE TO SELF -- COME BACK TO WE SHOULDNT HAVE TO DO THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Replicate Results of Other Papers\n",
    "Notably, the works of Krueger AB, Whitmore DM (2001) and Krueger (1999) estimates a linear regression of small class sizes with other covariates on an outcome of percentile test scores and finds a 5-6 percentile difference. In Figure 1, the leftmost square-shaped bullet point is being replicated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_trunc.index:\n",
    "    if df_trunc.loc[i, 'g1freelunch'] == 1 or df_trunc.loc[i, 'g2freelunch'] == 1 or df_trunc.loc[i, 'g3freelunch'] == 1 or df_trunc.loc[i, 'gkfreelunch'] == 1:\n",
    "        df_trunc.loc[i, 'gkfreelunch'] = 1\n",
    "    else:\n",
    "        df_trunc.loc[i, 'gkfreelunch'] = 0\n",
    "df_trunc = df_trunc.drop(columns=['g1freelunch', 'g2freelunch', 'g3freelunch'])\n",
    "\n",
    "df_trunc = df_trunc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecdf_reading = ECDF(df_trunc[df_trunc['treated'] == 0]['gktreadss'])\n",
    "ecdf_math = ECDF(df_trunc[df_trunc['treated'] == 0]['gktmathss'])\n",
    "df_trunc['read_outcome'] = ecdf_reading(df_trunc['gktreadss'])*100\n",
    "df_trunc['math_outcome'] = ecdf_math(df_trunc['gktmathss'])*100\n",
    "df_trunc['outcome'] = (df_trunc['read_outcome'] + df_trunc['math_outcome'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the fixed effects regression using (1) fixed effects regression package with just the school fixed effects and the treatment variable, (2) the fixed effects regression package with the treatment other variables and with school fixed effects, and (3) OLS with school variables, other variables, and the treated. Each time, we see approximately the same coefficients for the treated variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>   <td>outcome</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>No. Observations:</td>  <td>5120</td>         <td>Method:</td>          <td>REML</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>No. Groups:</td>      <td>79</td>          <td>Scale:</td>         <td>558.7809</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Min. group size:</td>    <td>30</td>        <td>Likelihood:</td>     <td>-23574.6243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Max. group size:</td>    <td>123</td>       <td>Converged:</td>          <td>Yes</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Mean group size:</td>   <td>64.8</td>            <td></td>                <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th> <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>51.109</td>    <td>1.536</td>  <td>33.284</td> <td>0.000</td> <td>48.099</td> <td>54.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treated</th>    <td>5.572</td>    <td>0.736</td>   <td>7.572</td> <td>0.000</td>  <td>4.130</td>  <td>7.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group Var</th> <td>173.039</td>   <td>1.245</td>     <td></td>      <td></td>       <td></td>       <td></td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "          Mixed Linear Model Regression Results\n",
       "=========================================================\n",
       "Model:            MixedLM Dependent Variable: outcome    \n",
       "No. Observations: 5120    Method:             REML       \n",
       "No. Groups:       79      Scale:              558.7809   \n",
       "Min. group size:  30      Likelihood:         -23574.6243\n",
       "Max. group size:  123     Converged:          Yes        \n",
       "Mean group size:  64.8                                   \n",
       "---------------------------------------------------------\n",
       "               Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
       "---------------------------------------------------------\n",
       "Intercept      51.109    1.536 33.284 0.000 48.099 54.119\n",
       "treated         5.572    0.736  7.572 0.000  4.130  7.014\n",
       "Group Var     173.039    1.245                           \n",
       "=========================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = smf.mixedlm(formula=\"outcome ~ treated\", data=df_trunc , groups=df_trunc['gkschid'])\n",
    "md.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>   <td>outcome</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>No. Observations:</td>  <td>5120</td>         <td>Method:</td>          <td>REML</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>No. Groups:</td>      <td>79</td>          <td>Scale:</td>         <td>517.1212</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Min. group size:</td>    <td>30</td>        <td>Likelihood:</td>     <td>-23369.5767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Max. group size:</td>    <td>123</td>       <td>Converged:</td>          <td>Yes</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Mean group size:</td>   <td>64.8</td>            <td></td>                <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>          <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th> <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>41.559</td>    <td>1.708</td>  <td>24.335</td> <td>0.000</td> <td>38.212</td> <td>44.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender[T.1]</th>      <td>-4.763</td>    <td>0.640</td>  <td>-7.440</td> <td>0.000</td> <td>-6.018</td> <td>-3.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gkfreelunch[T.0]</th> <td>12.274</td>    <td>0.771</td>  <td>15.928</td> <td>0.000</td> <td>10.764</td> <td>13.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race</th>              <td>9.296</td>    <td>1.277</td>   <td>7.278</td> <td>0.000</td>  <td>6.793</td> <td>11.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treated</th>           <td>5.579</td>    <td>0.708</td>   <td>7.881</td> <td>0.000</td>  <td>4.191</td>  <td>6.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group Var</th>        <td>147.623</td>   <td>1.111</td>     <td></td>      <td></td>       <td></td>       <td></td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "           Mixed Linear Model Regression Results\n",
       "============================================================\n",
       "Model:             MixedLM  Dependent Variable:  outcome    \n",
       "No. Observations:  5120     Method:              REML       \n",
       "No. Groups:        79       Scale:               517.1212   \n",
       "Min. group size:   30       Likelihood:          -23369.5767\n",
       "Max. group size:   123      Converged:           Yes        \n",
       "Mean group size:   64.8                                     \n",
       "------------------------------------------------------------\n",
       "                  Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
       "------------------------------------------------------------\n",
       "Intercept         41.559    1.708 24.335 0.000 38.212 44.906\n",
       "gender[T.1]       -4.763    0.640 -7.440 0.000 -6.018 -3.508\n",
       "gkfreelunch[T.0]  12.274    0.771 15.928 0.000 10.764 13.785\n",
       "race               9.296    1.277  7.278 0.000  6.793 11.800\n",
       "treated            5.579    0.708  7.881 0.000  4.191  6.966\n",
       "Group Var        147.623    1.111                           \n",
       "============================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = smf.mixedlm(formula=\"outcome ~ gender+race+gkfreelunch+treated\", data=df_trunc, groups=df_trunc['gkschid'])\n",
    "md.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>outcome</td>     <th>  R-squared:         </th> <td>   0.308</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.296</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.30</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 22 Feb 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:00:38</td>     <th>  Log-Likelihood:    </th> <td> -23219.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5120</td>      <th>  AIC:               </th> <td>4.660e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5037</td>      <th>  BIC:               </th> <td>4.715e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    82</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>   60.7510</td> <td>    2.771</td> <td>   21.927</td> <td> 0.000</td> <td>   55.319</td> <td>   66.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>112038.0</th>    <td>  -30.2353</td> <td>    4.043</td> <td>   -7.478</td> <td> 0.000</td> <td>  -38.162</td> <td>  -22.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>123056.0</th>    <td>  -17.4150</td> <td>    4.103</td> <td>   -4.244</td> <td> 0.000</td> <td>  -25.459</td> <td>   -9.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>128068.0</th>    <td>  -18.5177</td> <td>    3.934</td> <td>   -4.707</td> <td> 0.000</td> <td>  -26.231</td> <td>  -10.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>128076.0</th>    <td>  -24.7735</td> <td>    3.875</td> <td>   -6.393</td> <td> 0.000</td> <td>  -32.370</td> <td>  -17.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>128079.0</th>    <td>  -26.3821</td> <td>    3.865</td> <td>   -6.825</td> <td> 0.000</td> <td>  -33.960</td> <td>  -18.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>130085.0</th>    <td>  -18.0859</td> <td>    3.666</td> <td>   -4.933</td> <td> 0.000</td> <td>  -25.274</td> <td>  -10.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>159171.0</th>    <td>    9.8644</td> <td>    3.326</td> <td>    2.966</td> <td> 0.003</td> <td>    3.343</td> <td>   16.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>161176.0</th>    <td>  -16.6120</td> <td>    3.531</td> <td>   -4.704</td> <td> 0.000</td> <td>  -23.535</td> <td>   -9.689</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>162184.0</th>    <td>  -13.7527</td> <td>    3.888</td> <td>   -3.537</td> <td> 0.000</td> <td>  -21.375</td> <td>   -6.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>164198.0</th>    <td>  -10.1512</td> <td>    4.018</td> <td>   -2.526</td> <td> 0.012</td> <td>  -18.028</td> <td>   -2.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>165199.0</th>    <td>    2.6009</td> <td>    4.407</td> <td>    0.590</td> <td> 0.555</td> <td>   -6.039</td> <td>   11.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>166203.0</th>    <td>  -18.5101</td> <td>    4.285</td> <td>   -4.320</td> <td> 0.000</td> <td>  -26.911</td> <td>  -10.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>168211.0</th>    <td>  -10.0551</td> <td>    3.390</td> <td>   -2.966</td> <td> 0.003</td> <td>  -16.701</td> <td>   -3.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>168214.0</th>    <td>    2.5600</td> <td>    3.969</td> <td>    0.645</td> <td> 0.519</td> <td>   -5.220</td> <td>   10.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>169219.0</th>    <td>    2.9215</td> <td>    4.157</td> <td>    0.703</td> <td> 0.482</td> <td>   -5.227</td> <td>   11.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>169229.0</th>    <td>   -2.6218</td> <td>    3.420</td> <td>   -0.767</td> <td> 0.443</td> <td>   -9.327</td> <td>    4.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>169231.0</th>    <td>  -27.8323</td> <td>    3.994</td> <td>   -6.969</td> <td> 0.000</td> <td>  -35.662</td> <td>  -20.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>169280.0</th>    <td>   -3.5777</td> <td>    4.059</td> <td>   -0.882</td> <td> 0.378</td> <td>  -11.534</td> <td>    4.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>170295.0</th>    <td>   -3.0820</td> <td>    3.719</td> <td>   -0.829</td> <td> 0.407</td> <td>  -10.372</td> <td>    4.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>173312.0</th>    <td>   13.3713</td> <td>    3.893</td> <td>    3.435</td> <td> 0.001</td> <td>    5.740</td> <td>   21.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>176329.0</th>    <td>    5.5987</td> <td>    3.739</td> <td>    1.497</td> <td> 0.134</td> <td>   -1.731</td> <td>   12.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>180344.0</th>    <td>   -6.5009</td> <td>    3.426</td> <td>   -1.897</td> <td> 0.058</td> <td>  -13.218</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>189378.0</th>    <td>  -22.4983</td> <td>    3.657</td> <td>   -6.153</td> <td> 0.000</td> <td>  -29.667</td> <td>  -15.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>189382.0</th>    <td>  -11.2480</td> <td>    3.838</td> <td>   -2.931</td> <td> 0.003</td> <td>  -18.772</td> <td>   -3.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>189396.0</th>    <td>  -21.6991</td> <td>    3.839</td> <td>   -5.652</td> <td> 0.000</td> <td>  -29.225</td> <td>  -14.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>191411.0</th>    <td>   -2.9399</td> <td>    4.489</td> <td>   -0.655</td> <td> 0.513</td> <td>  -11.740</td> <td>    5.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>193422.0</th>    <td>    2.0550</td> <td>    3.800</td> <td>    0.541</td> <td> 0.589</td> <td>   -5.395</td> <td>    9.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>193423.0</th>    <td>   -4.1142</td> <td>    3.584</td> <td>   -1.148</td> <td> 0.251</td> <td>  -11.140</td> <td>    2.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>201449.0</th>    <td>    4.5665</td> <td>    3.465</td> <td>    1.318</td> <td> 0.188</td> <td>   -2.226</td> <td>   11.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>203452.0</th>    <td>  -13.7293</td> <td>    3.450</td> <td>   -3.980</td> <td> 0.000</td> <td>  -20.493</td> <td>   -6.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>203457.0</th>    <td>    5.4469</td> <td>    4.314</td> <td>    1.263</td> <td> 0.207</td> <td>   -3.010</td> <td>   13.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>205488.0</th>    <td>  -12.6341</td> <td>    4.053</td> <td>   -3.117</td> <td> 0.002</td> <td>  -20.581</td> <td>   -4.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>205489.0</th>    <td>  -10.6671</td> <td>    4.039</td> <td>   -2.641</td> <td> 0.008</td> <td>  -18.585</td> <td>   -2.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>205490.0</th>    <td>  -29.0381</td> <td>    4.010</td> <td>   -7.241</td> <td> 0.000</td> <td>  -36.899</td> <td>  -21.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>205491.0</th>    <td>  -15.6385</td> <td>    3.699</td> <td>   -4.228</td> <td> 0.000</td> <td>  -22.890</td> <td>   -8.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>205492.0</th>    <td>   11.1180</td> <td>    3.780</td> <td>    2.942</td> <td> 0.003</td> <td>    3.708</td> <td>   18.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>208501.0</th>    <td>  -11.3465</td> <td>    3.743</td> <td>   -3.032</td> <td> 0.002</td> <td>  -18.684</td> <td>   -4.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>208503.0</th>    <td>  -26.4575</td> <td>    4.205</td> <td>   -6.291</td> <td> 0.000</td> <td>  -34.702</td> <td>  -18.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>209510.0</th>    <td>  -18.2424</td> <td>    3.382</td> <td>   -5.393</td> <td> 0.000</td> <td>  -24.873</td> <td>  -11.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>212522.0</th>    <td>   -1.7798</td> <td>    3.757</td> <td>   -0.474</td> <td> 0.636</td> <td>   -9.145</td> <td>    5.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>215533.0</th>    <td>    3.9280</td> <td>    3.297</td> <td>    1.191</td> <td> 0.234</td> <td>   -2.535</td> <td>   10.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>216536.0</th>    <td>  -13.0463</td> <td>    3.293</td> <td>   -3.962</td> <td> 0.000</td> <td>  -19.502</td> <td>   -6.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>218562.0</th>    <td>   -1.5056</td> <td>    3.967</td> <td>   -0.379</td> <td> 0.704</td> <td>   -9.284</td> <td>    6.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>221571.0</th>    <td>  -37.5751</td> <td>    3.372</td> <td>  -11.143</td> <td> 0.000</td> <td>  -44.186</td> <td>  -30.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>221574.0</th>    <td>  -25.3079</td> <td>    3.905</td> <td>   -6.480</td> <td> 0.000</td> <td>  -32.964</td> <td>  -17.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>225585.0</th>    <td>  -18.0484</td> <td>    4.018</td> <td>   -4.492</td> <td> 0.000</td> <td>  -25.926</td> <td>  -10.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>228606.0</th>    <td>   -4.9242</td> <td>    3.599</td> <td>   -1.368</td> <td> 0.171</td> <td>  -11.979</td> <td>    2.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>230612.0</th>    <td>    9.2684</td> <td>    4.017</td> <td>    2.308</td> <td> 0.021</td> <td>    1.394</td> <td>   17.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>231616.0</th>    <td>    1.5437</td> <td>    3.986</td> <td>    0.387</td> <td> 0.699</td> <td>   -6.271</td> <td>    9.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>234628.0</th>    <td>   -5.5710</td> <td>    3.385</td> <td>   -1.646</td> <td> 0.100</td> <td>  -12.206</td> <td>    1.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244697.0</th>    <td>  -16.3281</td> <td>    3.598</td> <td>   -4.538</td> <td> 0.000</td> <td>  -23.383</td> <td>   -9.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244708.0</th>    <td>  -21.0232</td> <td>    3.519</td> <td>   -5.974</td> <td> 0.000</td> <td>  -27.923</td> <td>  -14.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244723.0</th>    <td>  -19.1247</td> <td>    3.730</td> <td>   -5.127</td> <td> 0.000</td> <td>  -26.437</td> <td>  -11.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244727.0</th>    <td>   -2.4849</td> <td>    3.749</td> <td>   -0.663</td> <td> 0.507</td> <td>   -9.834</td> <td>    4.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244728.0</th>    <td>  -15.6730</td> <td>    4.363</td> <td>   -3.592</td> <td> 0.000</td> <td>  -24.226</td> <td>   -7.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244736.0</th>    <td>   12.2426</td> <td>    4.271</td> <td>    2.866</td> <td> 0.004</td> <td>    3.870</td> <td>   20.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244745.0</th>    <td>    7.5161</td> <td>    3.646</td> <td>    2.062</td> <td> 0.039</td> <td>    0.369</td> <td>   14.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244746.0</th>    <td>    2.6394</td> <td>    4.190</td> <td>    0.630</td> <td> 0.529</td> <td>   -5.574</td> <td>   10.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244755.0</th>    <td>    1.3690</td> <td>    3.368</td> <td>    0.406</td> <td> 0.684</td> <td>   -5.234</td> <td>    7.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244764.0</th>    <td>   -4.2406</td> <td>    4.923</td> <td>   -0.861</td> <td> 0.389</td> <td>  -13.893</td> <td>    5.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244774.0</th>    <td>   -3.1740</td> <td>    3.537</td> <td>   -0.897</td> <td> 0.370</td> <td>  -10.108</td> <td>    3.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244776.0</th>    <td>   -7.6684</td> <td>    3.367</td> <td>   -2.278</td> <td> 0.023</td> <td>  -14.269</td> <td>   -1.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244780.0</th>    <td>   31.3916</td> <td>    4.029</td> <td>    7.791</td> <td> 0.000</td> <td>   23.493</td> <td>   39.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244796.0</th>    <td>   -9.8018</td> <td>    4.120</td> <td>   -2.379</td> <td> 0.017</td> <td>  -17.879</td> <td>   -1.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244799.0</th>    <td>   -8.2803</td> <td>    3.978</td> <td>   -2.081</td> <td> 0.037</td> <td>  -16.079</td> <td>   -0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244801.0</th>    <td>   -9.7699</td> <td>    3.674</td> <td>   -2.659</td> <td> 0.008</td> <td>  -16.972</td> <td>   -2.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244806.0</th>    <td>   20.3104</td> <td>    3.348</td> <td>    6.067</td> <td> 0.000</td> <td>   13.748</td> <td>   26.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244818.0</th>    <td>  -15.9656</td> <td>    3.669</td> <td>   -4.352</td> <td> 0.000</td> <td>  -23.158</td> <td>   -8.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244831.0</th>    <td>   -8.7976</td> <td>    4.111</td> <td>   -2.140</td> <td> 0.032</td> <td>  -16.857</td> <td>   -0.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>244839.0</th>    <td>   10.0934</td> <td>    3.843</td> <td>    2.626</td> <td> 0.009</td> <td>    2.559</td> <td>   17.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>252885.0</th>    <td>   -3.4895</td> <td>    3.711</td> <td>   -0.940</td> <td> 0.347</td> <td>  -10.765</td> <td>    3.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>253888.0</th>    <td>  -10.4277</td> <td>    4.396</td> <td>   -2.372</td> <td> 0.018</td> <td>  -19.046</td> <td>   -1.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>257899.0</th>    <td>  -18.1728</td> <td>    3.333</td> <td>   -5.452</td> <td> 0.000</td> <td>  -24.708</td> <td>  -11.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>257905.0</th>    <td>   -0.8072</td> <td>    3.194</td> <td>   -0.253</td> <td> 0.800</td> <td>   -7.069</td> <td>    5.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>259915.0</th>    <td>  -10.6673</td> <td>    3.962</td> <td>   -2.693</td> <td> 0.007</td> <td>  -18.434</td> <td>   -2.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>261927.0</th>    <td>   -8.9889</td> <td>    3.484</td> <td>   -2.580</td> <td> 0.010</td> <td>  -15.819</td> <td>   -2.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>262937.0</th>    <td>    6.1746</td> <td>    3.788</td> <td>    1.630</td> <td> 0.103</td> <td>   -1.252</td> <td>   13.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>264945.0</th>    <td>    1.4012</td> <td>    3.393</td> <td>    0.413</td> <td> 0.680</td> <td>   -5.251</td> <td>    8.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>      <td>   -4.7133</td> <td>    0.640</td> <td>   -7.360</td> <td> 0.000</td> <td>   -5.969</td> <td>   -3.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race</th>        <td>    9.8843</td> <td>    1.354</td> <td>    7.302</td> <td> 0.000</td> <td>    7.231</td> <td>   12.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gkfreelunch</th> <td>  -12.2654</td> <td>    0.775</td> <td>  -15.819</td> <td> 0.000</td> <td>  -13.785</td> <td>  -10.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treated</th>     <td>    5.6153</td> <td>    0.709</td> <td>    7.923</td> <td> 0.000</td> <td>    4.226</td> <td>    7.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>114.806</td> <th>  Durbin-Watson:     </th> <td>   1.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  73.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.158</td>  <th>  Prob(JB):          </th> <td>1.24e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.507</td>  <th>  Cond. No.          </th> <td>    98.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                outcome   R-squared:                       0.308\n",
       "Model:                            OLS   Adj. R-squared:                  0.296\n",
       "Method:                 Least Squares   F-statistic:                     27.30\n",
       "Date:                Wed, 22 Feb 2023   Prob (F-statistic):               0.00\n",
       "Time:                        11:00:38   Log-Likelihood:                -23219.\n",
       "No. Observations:                5120   AIC:                         4.660e+04\n",
       "Df Residuals:                    5037   BIC:                         4.715e+04\n",
       "Df Model:                          82                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const          60.7510      2.771     21.927      0.000      55.319      66.183\n",
       "112038.0      -30.2353      4.043     -7.478      0.000     -38.162     -22.308\n",
       "123056.0      -17.4150      4.103     -4.244      0.000     -25.459      -9.371\n",
       "128068.0      -18.5177      3.934     -4.707      0.000     -26.231     -10.805\n",
       "128076.0      -24.7735      3.875     -6.393      0.000     -32.370     -17.177\n",
       "128079.0      -26.3821      3.865     -6.825      0.000     -33.960     -18.804\n",
       "130085.0      -18.0859      3.666     -4.933      0.000     -25.274     -10.898\n",
       "159171.0        9.8644      3.326      2.966      0.003       3.343      16.385\n",
       "161176.0      -16.6120      3.531     -4.704      0.000     -23.535      -9.689\n",
       "162184.0      -13.7527      3.888     -3.537      0.000     -21.375      -6.130\n",
       "164198.0      -10.1512      4.018     -2.526      0.012     -18.028      -2.274\n",
       "165199.0        2.6009      4.407      0.590      0.555      -6.039      11.241\n",
       "166203.0      -18.5101      4.285     -4.320      0.000     -26.911     -10.109\n",
       "168211.0      -10.0551      3.390     -2.966      0.003     -16.701      -3.409\n",
       "168214.0        2.5600      3.969      0.645      0.519      -5.220      10.340\n",
       "169219.0        2.9215      4.157      0.703      0.482      -5.227      11.070\n",
       "169229.0       -2.6218      3.420     -0.767      0.443      -9.327       4.083\n",
       "169231.0      -27.8323      3.994     -6.969      0.000     -35.662     -20.003\n",
       "169280.0       -3.5777      4.059     -0.882      0.378     -11.534       4.379\n",
       "170295.0       -3.0820      3.719     -0.829      0.407     -10.372       4.208\n",
       "173312.0       13.3713      3.893      3.435      0.001       5.740      21.003\n",
       "176329.0        5.5987      3.739      1.497      0.134      -1.731      12.929\n",
       "180344.0       -6.5009      3.426     -1.897      0.058     -13.218       0.216\n",
       "189378.0      -22.4983      3.657     -6.153      0.000     -29.667     -15.330\n",
       "189382.0      -11.2480      3.838     -2.931      0.003     -18.772      -3.724\n",
       "189396.0      -21.6991      3.839     -5.652      0.000     -29.225     -14.173\n",
       "191411.0       -2.9399      4.489     -0.655      0.513     -11.740       5.860\n",
       "193422.0        2.0550      3.800      0.541      0.589      -5.395       9.504\n",
       "193423.0       -4.1142      3.584     -1.148      0.251     -11.140       2.912\n",
       "201449.0        4.5665      3.465      1.318      0.188      -2.226      11.359\n",
       "203452.0      -13.7293      3.450     -3.980      0.000     -20.493      -6.966\n",
       "203457.0        5.4469      4.314      1.263      0.207      -3.010      13.903\n",
       "205488.0      -12.6341      4.053     -3.117      0.002     -20.581      -4.688\n",
       "205489.0      -10.6671      4.039     -2.641      0.008     -18.585      -2.749\n",
       "205490.0      -29.0381      4.010     -7.241      0.000     -36.899     -21.177\n",
       "205491.0      -15.6385      3.699     -4.228      0.000     -22.890      -8.387\n",
       "205492.0       11.1180      3.780      2.942      0.003       3.708      18.528\n",
       "208501.0      -11.3465      3.743     -3.032      0.002     -18.684      -4.009\n",
       "208503.0      -26.4575      4.205     -6.291      0.000     -34.702     -18.213\n",
       "209510.0      -18.2424      3.382     -5.393      0.000     -24.873     -11.612\n",
       "212522.0       -1.7798      3.757     -0.474      0.636      -9.145       5.585\n",
       "215533.0        3.9280      3.297      1.191      0.234      -2.535      10.391\n",
       "216536.0      -13.0463      3.293     -3.962      0.000     -19.502      -6.590\n",
       "218562.0       -1.5056      3.967     -0.379      0.704      -9.284       6.272\n",
       "221571.0      -37.5751      3.372    -11.143      0.000     -44.186     -30.964\n",
       "221574.0      -25.3079      3.905     -6.480      0.000     -32.964     -17.652\n",
       "225585.0      -18.0484      4.018     -4.492      0.000     -25.926     -10.171\n",
       "228606.0       -4.9242      3.599     -1.368      0.171     -11.979       2.131\n",
       "230612.0        9.2684      4.017      2.308      0.021       1.394      17.143\n",
       "231616.0        1.5437      3.986      0.387      0.699      -6.271       9.358\n",
       "234628.0       -5.5710      3.385     -1.646      0.100     -12.206       1.064\n",
       "244697.0      -16.3281      3.598     -4.538      0.000     -23.383      -9.274\n",
       "244708.0      -21.0232      3.519     -5.974      0.000     -27.923     -14.124\n",
       "244723.0      -19.1247      3.730     -5.127      0.000     -26.437     -11.812\n",
       "244727.0       -2.4849      3.749     -0.663      0.507      -9.834       4.865\n",
       "244728.0      -15.6730      4.363     -3.592      0.000     -24.226      -7.120\n",
       "244736.0       12.2426      4.271      2.866      0.004       3.870      20.616\n",
       "244745.0        7.5161      3.646      2.062      0.039       0.369      14.663\n",
       "244746.0        2.6394      4.190      0.630      0.529      -5.574      10.853\n",
       "244755.0        1.3690      3.368      0.406      0.684      -5.234       7.972\n",
       "244764.0       -4.2406      4.923     -0.861      0.389     -13.893       5.412\n",
       "244774.0       -3.1740      3.537     -0.897      0.370     -10.108       3.759\n",
       "244776.0       -7.6684      3.367     -2.278      0.023     -14.269      -1.068\n",
       "244780.0       31.3916      4.029      7.791      0.000      23.493      39.290\n",
       "244796.0       -9.8018      4.120     -2.379      0.017     -17.879      -1.725\n",
       "244799.0       -8.2803      3.978     -2.081      0.037     -16.079      -0.481\n",
       "244801.0       -9.7699      3.674     -2.659      0.008     -16.972      -2.567\n",
       "244806.0       20.3104      3.348      6.067      0.000      13.748      26.873\n",
       "244818.0      -15.9656      3.669     -4.352      0.000     -23.158      -8.773\n",
       "244831.0       -8.7976      4.111     -2.140      0.032     -16.857      -0.738\n",
       "244839.0       10.0934      3.843      2.626      0.009       2.559      17.628\n",
       "252885.0       -3.4895      3.711     -0.940      0.347     -10.765       3.786\n",
       "253888.0      -10.4277      4.396     -2.372      0.018     -19.046      -1.809\n",
       "257899.0      -18.1728      3.333     -5.452      0.000     -24.708     -11.638\n",
       "257905.0       -0.8072      3.194     -0.253      0.800      -7.069       5.454\n",
       "259915.0      -10.6673      3.962     -2.693      0.007     -18.434      -2.901\n",
       "261927.0       -8.9889      3.484     -2.580      0.010     -15.819      -2.159\n",
       "262937.0        6.1746      3.788      1.630      0.103      -1.252      13.601\n",
       "264945.0        1.4012      3.393      0.413      0.680      -5.251       8.054\n",
       "gender         -4.7133      0.640     -7.360      0.000      -5.969      -3.458\n",
       "race            9.8843      1.354      7.302      0.000       7.231      12.538\n",
       "gkfreelunch   -12.2654      0.775    -15.819      0.000     -13.785     -10.745\n",
       "treated         5.6153      0.709      7.923      0.000       4.226       7.005\n",
       "==============================================================================\n",
       "Omnibus:                      114.806   Durbin-Watson:                   1.865\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               73.250\n",
       "Skew:                          -0.158   Prob(JB):                     1.24e-16\n",
       "Kurtosis:                       2.507   Cond. No.                         98.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fes = pd.get_dummies(df_trunc['gkschid'])\n",
    "fes = fes.drop(columns=[161183.0]) # have to drop one before running a fixed effects regression\n",
    "y = df_trunc.loc[:,['outcome']]\n",
    "x = df_trunc.loc[:, ['gender', 'race', 'gkfreelunch', 'treated']]\n",
    "x = pd.concat([fes,x],axis=1)\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y,x)\n",
    "model.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successful replication of these results builds confidence in proper data cleaning methodology so we proceed to explore inference on this dataset with the dame-flame package.\n",
    "## 3. dame-flame on this dataset -- using the percentile outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_drop = df_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trunc = df_trunc.drop(columns=['gktreadss', 'gktmathss', 'read_outcome', 'math_outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>gkschid</th>\n",
       "      <th>gksurban</th>\n",
       "      <th>gktgen</th>\n",
       "      <th>gktrace</th>\n",
       "      <th>gkthighdegree</th>\n",
       "      <th>gkfreelunch</th>\n",
       "      <th>treated</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169280.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.450586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>218562.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70.212172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205492.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.538805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>257899.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>79.299274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.398102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender  race   gkschid gksurban gktgen gktrace  gkthighdegree gkfreelunch  \\\n",
       "133      1   0.0  169280.0        2      0       1            0.0           0   \n",
       "246      0   1.0  218562.0        1      0       1            1.0           1   \n",
       "263      0   0.0  205492.0        2      0       1            0.0           1   \n",
       "266      1   1.0  257899.0        0      0       1            1.0           0   \n",
       "275      1   1.0  161176.0        0      0       1            0.0           1   \n",
       "\n",
       "     treated  age    outcome  \n",
       "133      0.0  5.0  48.450586  \n",
       "246      0.0  9.0  70.212172  \n",
       "263      1.0  2.0  85.538805  \n",
       "266      0.0  2.0  79.299274  \n",
       "275      0.0  2.0  32.398102  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trunc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5120"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching stopped while attempting iteration 28 due to the PE fraction early stopping criterion.\n",
      "\tPredictive error of covariate set would have been 92.12026755312186\n",
      "Matching stopped while attempting iteration 20 due to the PE fraction early stopping criterion.\n",
      "\tPredictive error of covariate set would have been 105.55615864739742\n",
      "Matching stopped while attempting iteration 16 due to the PE fraction early stopping criterion.\n",
      "\tPredictive error of covariate set would have been 126.2251752950491\n",
      "Matching stopped while attempting iteration 20 due to the PE fraction early stopping criterion.\n",
      "\tPredictive error of covariate set would have been 64.27750359184846\n"
     ]
    }
   ],
   "source": [
    "# Do the matching\n",
    "\n",
    "models = []\n",
    "random_seeds = [1111, 2222, 3333, 4444]\n",
    "for i in range(4):\n",
    "    matching_df, holdout_df = train_test_split(df_trunc, test_size=0.2, random_state=random_seeds[i])\n",
    "    model_dame = dame_flame.matching.DAME(\n",
    "        repeats=False, verbose=0, adaptive_weights='decisiontree', early_stop_pe=0.33)\n",
    "    model_dame.fit(holdout_data=holdout_df)\n",
    "    model_dame.predict(matching_df)\n",
    "    models.append(model_dame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 matched 1882 units with an ATE of 5.11 and a variance of ATE of 1.35\n",
      "Trial 1 matched 1904 units with an ATE of 5.95 and a variance of ATE of 1.34\n",
      "Trial 2 matched 1814 units with an ATE of 4.98 and a variance of ATE of 1.44\n",
      "Trial 3 matched 1790 units with an ATE of 5.3 and a variance of ATE of 1.41\n"
     ]
    }
   ],
   "source": [
    "ates = []\n",
    "for i in range(len(models)):\n",
    "    var, ate = dame_flame.utils.post_processing.var_ATE(matching_object=models[i])\n",
    "    print(\"Trial\", i, \"matched\", len(models[i].df_units_and_covars_matched), \"units with an ATE of\", round(ate,2), \"and a variance of ATE of\", round(var,2))\n",
    "    ates.append(ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration 0 of matching\n",
      "\tNumber of matched groups formed in total:  358\n",
      "\tUnmatched treated units:  783 out of a total of  1227 treated units\n",
      "\tUnmatched control units:  2234 out of a total of  2869 control units\n",
      "\tNumber of matches made this iteration:  1079\n",
      "\tNumber of matches made so far:  1079\n",
      "\tCovariates dropped so far:  set()\n",
      "\tPredictive error of covariate set used to match:  63.99210023248127\n",
      "Completed iteration 1 of matching\n",
      "\tNumber of matched groups formed in total:  358\n",
      "\tUnmatched treated units:  783 out of a total of  1227 treated units\n",
      "\tUnmatched control units:  2234 out of a total of  2869 control units\n",
      "\tNumber of matches made this iteration:  0\n",
      "\tNumber of matches made so far:  1079\n",
      "\tCovariates dropped so far:  gktgen\n",
      "\tPredictive error of covariate set used to match:  63.992100232481256\n",
      "Completed iteration 2 of matching\n",
      "\tNumber of matched groups formed in total:  358\n",
      "\tUnmatched treated units:  783 out of a total of  1227 treated units\n",
      "\tUnmatched control units:  2234 out of a total of  2869 control units\n",
      "\tNumber of matches made this iteration:  0\n",
      "\tNumber of matches made so far:  1079\n",
      "\tCovariates dropped so far:  gksurban\n",
      "\tPredictive error of covariate set used to match:  63.992100232481256\n",
      "Completed iteration 3 of matching\n",
      "\tNumber of matched groups formed in total:  420\n",
      "\tUnmatched treated units:  694 out of a total of  1227 treated units\n",
      "\tUnmatched control units:  2125 out of a total of  2869 control units\n",
      "\tNumber of matches made this iteration:  198\n",
      "\tNumber of matches made so far:  1277\n",
      "\tCovariates dropped so far:  gktrace\n",
      "\tPredictive error of covariate set used to match:  66.62725028943524\n",
      "Completed iteration 4 of matching\n",
      "\tNumber of matched groups formed in total:  451\n",
      "\tUnmatched treated units:  660 out of a total of  1227 treated units\n",
      "\tUnmatched control units:  2088 out of a total of  2869 control units\n",
      "\tNumber of matches made this iteration:  269\n",
      "\tNumber of matches made so far:  1348\n",
      "\tCovariates dropped so far:  race\n",
      "\tPredictive error of covariate set used to match:  73.1665664664769\n",
      "Matching stopped while attempting iteration 5 due to the PE fraction early stopping criterion.\n",
      "\tPredictive error of covariate set would have been 92.12026755312186\n",
      "Completed iteration 0 of matching\n",
      "\tNumber of matched groups formed in total:  347\n",
      "\tUnmatched treated units:  788 out of a total of  1232 treated units\n",
      "\tUnmatched control units:  2255 out of a total of  2864 control units\n",
      "\tNumber of matches made this iteration:  1053\n",
      "\tNumber of matches made so far:  1053\n",
      "\tCovariates dropped so far:  set()\n",
      "\tPredictive error of covariate set used to match:  77.89076825798355\n",
      "Completed iteration 1 of matching\n",
      "\tNumber of matched groups formed in total:  347\n",
      "\tUnmatched treated units:  788 out of a total of  1232 treated units\n",
      "\tUnmatched control units:  2255 out of a total of  2864 control units\n",
      "\tNumber of matches made this iteration:  0\n",
      "\tNumber of matches made so far:  1053\n",
      "\tCovariates dropped so far:  gktgen\n",
      "\tPredictive error of covariate set used to match:  77.89076825798355\n",
      "Completed iteration 2 of matching\n",
      "\tNumber of matched groups formed in total:  347\n",
      "\tUnmatched treated units:  788 out of a total of  1232 treated units\n",
      "\tUnmatched control units:  2255 out of a total of  2864 control units\n",
      "\tNumber of matches made this iteration:  0\n",
      "\tNumber of matches made so far:  1053\n",
      "\tCovariates dropped so far:  gksurban\n",
      "\tPredictive error of covariate set used to match:  77.89076825798355\n",
      "Completed iteration 3 of matching\n",
      "\tNumber of matched groups formed in total:  369\n",
      "\tUnmatched treated units:  760 out of a total of  1232 treated units\n",
      "\tUnmatched control units:  2230 out of a total of  2864 control units\n",
      "\tNumber of matches made this iteration:  53\n",
      "\tNumber of matches made so far:  1106\n",
      "\tCovariates dropped so far:  race\n",
      "\tPredictive error of covariate set used to match:  83.32993454065647\n",
      "Completed iteration 4 of matching\n",
      "\tNumber of matched groups formed in total:  436\n",
      "\tUnmatched treated units:  668 out of a total of  1232 treated units\n",
      "\tUnmatched control units:  2110 out of a total of  2864 control units\n",
      "\tNumber of matches made this iteration:  265\n",
      "\tNumber of matches made so far:  1318\n",
      "\tCovariates dropped so far:  gktrace\n",
      "\tPredictive error of covariate set used to match:  99.8824140808448\n",
      "Matching stopped while attempting iteration 5 due to the PE fraction early stopping criterion.\n",
      "\tPredictive error of covariate set would have been 130.13465965577228\n",
      "Completed iteration 0 of matching\n",
      "\tNumber of matched groups formed in total:  348\n",
      "\tUnmatched treated units:  779 out of a total of  1224 treated units\n",
      "\tUnmatched control units:  2270 out of a total of  2872 control units\n",
      "\tNumber of matches made this iteration:  1047\n",
      "\tNumber of matches made so far:  1047\n",
      "\tCovariates dropped so far:  set()\n",
      "\tPredictive error of covariate set used to match:  90.18915993961674\n",
      "Completed iteration 1 of matching\n",
      "\tNumber of matched groups formed in total:  348\n",
      "\tUnmatched treated units:  779 out of a total of  1224 treated units\n",
      "\tUnmatched control units:  2270 out of a total of  2872 control units\n",
      "\tNumber of matches made this iteration:  0\n",
      "\tNumber of matches made so far:  1047\n",
      "\tCovariates dropped so far:  gktgen\n",
      "\tPredictive error of covariate set used to match:  90.18915993961674\n",
      "Completed iteration 2 of matching\n",
      "\tNumber of matched groups formed in total:  348\n",
      "\tUnmatched treated units:  779 out of a total of  1224 treated units\n",
      "\tUnmatched control units:  2270 out of a total of  2872 control units\n",
      "\tNumber of matches made this iteration:  0\n",
      "\tNumber of matches made so far:  1047\n",
      "\tCovariates dropped so far:  gksurban\n",
      "\tPredictive error of covariate set used to match:  90.18915993961674\n",
      "Completed iteration 3 of matching\n",
      "\tNumber of matched groups formed in total:  415\n",
      "\tUnmatched treated units:  684 out of a total of  1224 treated units\n",
      "\tUnmatched control units:  2156 out of a total of  2872 control units\n",
      "\tNumber of matches made this iteration:  209\n",
      "\tNumber of matches made so far:  1256\n",
      "\tCovariates dropped so far:  gktrace\n",
      "\tPredictive error of covariate set used to match:  92.88507400288951\n",
      "Completed iteration 4 of matching\n",
      "\tNumber of matched groups formed in total:  448\n",
      "\tUnmatched treated units:  649 out of a total of  1224 treated units\n",
      "\tUnmatched control units:  2118 out of a total of  2872 control units\n",
      "\tNumber of matches made this iteration:  282\n",
      "\tNumber of matches made so far:  1329\n",
      "\tCovariates dropped so far:  race\n",
      "\tPredictive error of covariate set used to match:  100.97588976385877\n",
      "Matching stopped while attempting iteration 5 due to the PE fraction early stopping criterion.\n",
      "\tPredictive error of covariate set would have been 144.18842694993984\n",
      "Completed iteration 0 of matching\n",
      "\tNumber of matched groups formed in total:  356\n",
      "\tUnmatched treated units:  790 out of a total of  1236 treated units\n",
      "\tUnmatched control units:  2250 out of a total of  2860 control units\n",
      "\tNumber of matches made this iteration:  1056\n",
      "\tNumber of matches made so far:  1056\n",
      "\tCovariates dropped so far:  set()\n",
      "\tPredictive error of covariate set used to match:  44.00187154951203\n",
      "Completed iteration 1 of matching\n",
      "\tNumber of matched groups formed in total:  356\n",
      "\tUnmatched treated units:  790 out of a total of  1236 treated units\n",
      "\tUnmatched control units:  2250 out of a total of  2860 control units\n",
      "\tNumber of matches made this iteration:  0\n",
      "\tNumber of matches made so far:  1056\n",
      "\tCovariates dropped so far:  gktgen\n",
      "\tPredictive error of covariate set used to match:  44.00187154951203\n",
      "Completed iteration 2 of matching\n",
      "\tNumber of matched groups formed in total:  356\n",
      "\tUnmatched treated units:  790 out of a total of  1236 treated units\n",
      "\tUnmatched control units:  2250 out of a total of  2860 control units\n",
      "\tNumber of matches made this iteration:  0\n",
      "\tNumber of matches made so far:  1056\n",
      "\tCovariates dropped so far:  gksurban\n",
      "\tPredictive error of covariate set used to match:  44.00187154951203\n",
      "Completed iteration 3 of matching\n",
      "\tNumber of matched groups formed in total:  377\n",
      "\tUnmatched treated units:  765 out of a total of  1236 treated units\n",
      "\tUnmatched control units:  2221 out of a total of  2860 control units\n",
      "\tNumber of matches made this iteration:  54\n",
      "\tNumber of matches made so far:  1110\n",
      "\tCovariates dropped so far:  race\n",
      "\tPredictive error of covariate set used to match:  46.998880571836175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration 4 of matching\n",
      "\tNumber of matched groups formed in total:  444\n",
      "\tUnmatched treated units:  677 out of a total of  1236 treated units\n",
      "\tUnmatched control units:  2111 out of a total of  2860 control units\n",
      "\tNumber of matches made this iteration:  252\n",
      "\tNumber of matches made so far:  1308\n",
      "\tCovariates dropped so far:  gktrace\n",
      "\tPredictive error of covariate set used to match:  54.48113724290326\n",
      "Matching stopped while attempting iteration 5 due to the PE fraction early stopping criterion.\n",
      "\tPredictive error of covariate set would have been 72.44001302089018\n"
     ]
    }
   ],
   "source": [
    "## FLAME on the outcome instead.\n",
    "## This is the information that goes into Table 2 of the paper.\n",
    "flame_models = []\n",
    "random_seeds = [1111, 2222, 3333, 4444]\n",
    "for i in range(4):\n",
    "    matching_df, holdout_df = train_test_split(df_trunc, test_size=0.2, random_state=random_seeds[i])\n",
    "    model_flame = dame_flame.matching.FLAME(\n",
    "        repeats=False, verbose=3, adaptive_weights='decisiontree',\n",
    "        early_stop_pe=0.33)\n",
    "    model_flame.fit(holdout_data=holdout_df, outcome_column_name='outcome')\n",
    "    result_flame = model_flame.predict(matching_df)\n",
    "    flame_models.append(model_flame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(flame_models)):\n",
    "    var, ate = dame_flame.utils.post_processing.var_ATE(matching_object=flame_models[i])\n",
    "    print(\"Trial\", i, \"matched\", len(flame_models[i].df_units_and_covars_matched), \"units with an ATE of\", round(ate,2), \"and a variance of ATE of\", round(var,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute stuff for plot\n",
    "match_dfs = []\n",
    "for i in models:\n",
    "    match_dfs.append(i.input_data)\n",
    "\n",
    "for i in range(4):\n",
    "    colname = 'cates'\n",
    "    match_dfs[i][colname] = dame_flame.utils.post_processing.CATE(\n",
    "        models[i], match_dfs[i].index)\n",
    "\n",
    "dame_len_groups = []\n",
    "dame_cate_of_groups = []\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    model_dame = models[i]\n",
    "    groups = list(range(len(model_dame.units_per_group)))\n",
    "\n",
    "    dame_cate_of_group = []\n",
    "    dame_len_group = []\n",
    "    dame_len_treated = []\n",
    "    maxcate = 0.0\n",
    "    maxgroupnum = 0\n",
    "    index = 0\n",
    "\n",
    "    flame_cate_of_group = []\n",
    "    flame_len_group = []\n",
    "    large_groups = []\n",
    "    for group in model_dame.units_per_group:\n",
    "        dame_cate_of_group.append(dame_flame.utils.post_processing.CATE(\n",
    "            model_dame, group[0]))\n",
    "        dame_len_group.append(len(group))\n",
    "\n",
    "        # find len of just treated units\n",
    "        df_mmg = df_trunc.loc[group]\n",
    "        treated = df_mmg.loc[df_mmg[\"treated\"] == 1]\n",
    "\n",
    "    dame_len_groups.append(dame_len_group)\n",
    "    dame_cate_of_groups.append(dame_cate_of_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot, Figure 2 in the paper\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (19,13), \n",
    "                                             sharex=True, sharey=True)\n",
    "fig.text(0.5, 0.05, 'Number of Units in Matched Group', ha='center', \n",
    "         fontsize=26)\n",
    "fig.text(0.05, 0.5, 'Log Transformed Treatment Effect of Matched Group', \n",
    "         va='center', rotation='vertical', fontsize=26)\n",
    "fig.suptitle(\"CATE Estimates from DAME for Four Random Samples from STAR Dataset\", fontsize=28, y=0.91)\n",
    "ax1.axhline(y=np.log10(ates[0]), color='r', linestyle='-')\n",
    "ax2.axhline(y=np.log10(ates[1]), color='r', linestyle='-')\n",
    "ax3.axhline(y=np.log10(ates[2]), color='r', linestyle='-')\n",
    "ax4.axhline(y=np.log10(ates[3]), color='r', linestyle='-')\n",
    "\n",
    "ax1.tick_params(labelsize=26)\n",
    "ax2.tick_params(labelsize=26)\n",
    "ax3.tick_params(labelsize=26)\n",
    "ax4.tick_params(labelsize=26)\n",
    "\n",
    "al=0.2\n",
    "\n",
    "temp = np.array(dame_cate_of_groups[0])\n",
    "result = np.log10(temp, where=temp>0, out=temp)\n",
    "result = -1*np.log10(result*-1, where=result<0,out=result*-1)\n",
    "ax1.scatter(dame_len_groups[0], result, color=\"purple\", \n",
    "            alpha = al)\n",
    "ax1.text(0.8, 0.9,'ATE: '+str(round(ates[0],2)), ha='center', va='center',\n",
    "         transform=ax1.transAxes, fontsize=26)\n",
    "\n",
    "temp = np.array(dame_cate_of_groups[1])\n",
    "result = np.log10(temp, where=temp>0, out=temp)\n",
    "result = -1*np.log10(result*-1, where=result<0,out=result*-1)\n",
    "ax2.scatter(dame_len_groups[1], result, color=\"green\", \n",
    "            alpha = al)\n",
    "ax2.text(0.8, 0.9,'ATE: '+str(round(ates[1],2)), ha='center', va='center',\n",
    "         transform=ax2.transAxes, fontsize=26)\n",
    "\n",
    "temp = np.array(dame_cate_of_groups[2])\n",
    "result = np.log10(temp, where=temp>0, out=temp)\n",
    "result = -1*np.log10(result*-1, where=result<0,out=result*-1)\n",
    "ax3.scatter(dame_len_groups[2], result, color=\"blue\", \n",
    "            alpha = al)\n",
    "ax3.text(0.8, 0.9,'ATE: '+str(round(ates[2],2)), ha='center', va='center',\n",
    "         transform=ax3.transAxes, fontsize=26)\n",
    "\n",
    "temp = np.array(dame_cate_of_groups[3])\n",
    "result = np.log10(temp, where=temp>0, out=temp)\n",
    "result = -1*np.log10(result*-1, where=result<0,out=result*-1)\n",
    "ax4.scatter(dame_len_groups[3], result, color=\"magenta\",\n",
    "            alpha = al)\n",
    "ax4.text(0.8, 0.9,'ATE: '+str(round(ates[3],2)), ha='center', va='center',\n",
    "         transform=ax4.transAxes, fontsize=26)\n",
    "\n",
    "plt.subplots_adjust(wspace=.02, hspace=.02)\n",
    "plt.savefig('cate-graph4.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
