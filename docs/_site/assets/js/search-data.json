{"0": {
    "doc": "FAQ and Vocabulary Guide",
    "title": "FAQ and Vocabulary Guide",
    "content": ". | Vocabulary Guide | FAQ . | Why Don’t You Support Continuous Data? | Why doesn’t the machine learning step support my preferred method? | Why doesn’t the package have any built-in visualization methods? | Why should I use this instead of another package? Other ones seem more common! | . | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/FAQ",
    "relUrl": "/FAQ"
  },"1": {
    "doc": "FAQ and Vocabulary Guide",
    "title": "Vocabulary Guide",
    "content": "We briefly define some of the terms we use interchangeably throughout this User Guide and in this documentation below. | Unit, Observation, Individual | A participant in the research trial, in either the control group or treatment group, for whom we have an observed outcome | . | Covariate, Observed data, X’s, Independent variables | The data we observe which is not the treatment group or the outcome | . | Outcome, Y, Dependent variables | The outcome variable of the research | . | Treated Unit | A unit which is in the treatment group | . | Treatment Effects | We have a whole page on this. See here. | . | Matched group, matches | The group that a unit is assigned to based on the result of the matching algorithm | . | Main matched group | If units are assigned to multiple groups, each group has one group which is its main group, in which it is matched to units which it is most similar to. Other groups it is in will have less similar covariates | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/FAQ#vocabulary-guide",
    "relUrl": "/FAQ#vocabulary-guide"
  },"2": {
    "doc": "FAQ and Vocabulary Guide",
    "title": "FAQ",
    "content": "Why Don’t You Support Continuous Data? . The DAME-FLAME package implements the DAME and FLAME algorithms, which are designed to find the best matches on datasets that are discrete. We believe this package will be useful for researchers regardless, due to the existence of several research problems that do rely on discrete data. Why doesn’t the machine learning step support my preferred method? . At this time, we have provided implementations for three options: ridge regressions with a pre-specified alpha, ridge regressions with cross validation, and decision trees. We chose these based on what we know researchers want at this time. We definitely would love to add more if you wish! Please see our contributing guide. Why doesn’t the package have any built-in visualization methods? . Visualizing data is a valuable tool to understanding it before and after performing any analysis like matching. While the DAME-FLAME package doesn’t have built in functions to visualize the data, we provide several examples of ways that researchers could visualize any dataset, before and after matching. This is a listing: . | A histogram depicting the size of the matched group of each unit here | A scatter plot of true vs estimated CATT for units in a matched dataset here | A bar chart depicting the treatment effects of different matched groups here | A histogram depicting the size of each matched group here | A histogram of the number of units matched on each covariate, to help interpret covariate importance here | . For each of these, we provide a link to our github repository, and encourage users to fork the code and visualize your own data. Why should I use this instead of another package? Other ones seem more common! . We know lots of other matching algorithms are popular. We won’t become more common unless people like you will consider using us anyways, and we hope you’ll spread the word once you decide you like DAME-FLAME :) . We believe that the algorithms other matching packages rely on result in low-quality, uninterpretable matches. We define low-quality matches as matches with poor treatment effect estimates, and uninterpretable matches as the inability to determine from a match which covariates influence the decision of matched units. The most popular matching algorithm is propensity score matching. Coarsened Exact Matching is another popular technique. Propensity score matching reduces a dataset to one dimension, so matches are produced without an aim of highlighting important covariates. Coarsened exact matching also pre-defines distance metrics, which will often be dominated by irrelevant covariates (Dieng, et al.). Causal Forests are gaining popularity too, but we claim that isn’t a matching method in Wang, et al.. Please see our simulation here comparing DAME-FLAME against MatchIt’s propensity score matching. This simulation shows that our package results in higher-quality matches. Lastly, we hope you’ll consider using DAME-FLAME when you compare the features of the DAME-FLAME package against other popular matching packages that implement the algorithms discussed above. We offer several built-in treatment effect estimators so that users don’t have to rely on other packages or compute their own, and we offer built-in missing data handling. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/FAQ#faq",
    "relUrl": "/FAQ#faq"
  },"3": {
    "doc": "DAME",
    "title": "dame_flame.matching.DAME",
    "content": "class dame_flame.matching.DAME(adaptive_weights='ridge', alpha=0.1, repeats=True, verbose=2, early_stop_iterations=False, stop_unmatched_c=False, early_stop_un_c_frac=False, stop_unmatched_t=False, early_stop_un_t_frac=False, early_stop_pe=False, early_stop_pe_frac=0.01, early_stop_bf=False, early_stop_bf_frac=0.01, missing_indicator=np.nan, missing_data_replace=0, missing_holdout_replace=0, missing_holdout_imputations=10, missing_data_imputations=1, want_pe=False, want_bf=False) . Source Code . This class creates the matches based on the DAME “Dynamic Almost Matching Exactly” algorithm. It has built in support for stopping criteria and missing data handling. Read more in the User Guide . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/DAME#dame_flamematchingdame",
    "relUrl": "/documentation/api-documentation/DAME#dame_flamematchingdame"
  },"4": {
    "doc": "DAME",
    "title": "Parameters",
    "content": "| Parameter Name | Type | Default | Description | . | adaptive_weights | {bool, ‘ridge’, ‘decision tree’, ‘ridgeCV’} | ‘ridge’ | The method used to decide what covariate set should be dropped next. | . | alpha | float | 0.1 | If adaptive_weights is set to ridge, this is the alpha for ridge regression. | . | repeats | bool | True | Whether or not units for whom a main matched has been found can be used again, and placed in an auxiliary matched group. | . | verbose | int: {0,1,2,3} | 2 | Style of printout while algorithm runs. If 0, no output. If 1, provides iteration number. If 2, provides iteration number and additional information on the progress of the matching at every 10th iteration. If 3, provides iteration number and additional information on the progress of the matching at every iteration | . | early_stop_iterations | int | 0 | If provided, a number of iterations after which to hard stop the algorithm. | . | stop_unmatched_c | bool | False | If True, then the algorithm terminates when there are no more control units to match. | . | stop_unmatched_t | bool | False | If True, then the algorithm terminates when there are no more treatment units to match. | . | early_stop_un_c_frac | float | 0.1 | Must be between 0.0 and 1.0. This provides a fraction of unmatched control units. When the threshold is met, the algorithm will stop iterating. For example, using an input dataset with 100 control units, the algorithm will stop when 10 control units are unmatched and 90 are matched (or earlier, depending on other stopping conditions). | . | early_stop_un_t_frac | float | 0.1 | Must be between 0.0 and 1.0. This provides a fraction of unmatched treatment units. When the threshold is met, the algorithm will stop iterating. For example, using an input dataset with 100 treatment units, the algorithm will stop when 10 control units are unmatched and 90 are matched (or earlier, depending on other stopping conditions). | . | early_stop_pe | bool | False | If this is true, then if the covariate set chosen for matching has a predictive error higher than the parameter early_stop_pe_frac, the algorithm will stop. | . | early_stop_pe_frac | float | 0.01 | If early_stop_pe is true, then if the covariate set chosen for matching has a predictive error higher than this value, the algorithm will stop. | . | early_stop_bf | bool | False | If this is true, then if the covariate set chosen for matching has a balancing factor lower than early_stop_bf_frac, then the algorithm will stop. | . | early_stop_bf_frac | float | 0.01 | If early_stop_bf is true, then if the covariate set chosen for matching has a balancing factor lower than this value, then the algorithm will stop. | . | want_pe | bool | False | If true, the output of the algorithm will include the predictive error of the covariate sets used for matching in each iteration. | . | want_bf | bool | False | If true, the output will include the balancing factor for each iteration. | . | missing_indicator | {character, integer, numpy.nan} | numpy.nan | This is the indicator for missing data in the dataset. | . | missing_holdout_replace | int: {0,1,2} | 0 | If 0, assume no missing holdout data and proceed. If 1, the algorithm excludes units with missing values from the holdout dataset. If 2, do MICE on holdout dataset. If this option is selected, it will be done for a number of iterations equal to missing_holdout_imputations. | . | missing_data_replace | int: {0,1,2,3} | 0 | If 0, assume no missing data in matching data and proceed. If 1, the algorithm does not match on units that have missing values. If 2, prevent all missing_indicator values from being matched on. If 3, do MICE on matching dataset. This is not recommended. If this option is selected, it will be done for a number of iterations equal to missing_data_imputations. | . | missing_holdout_imputations | int | 10 | If missing_holdout_replace=2, the number of imputations. | . | missing_data_imputations | int | 1 | If missing_data_replace=3, the number of imputations. | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/DAME#parameters",
    "relUrl": "/documentation/api-documentation/DAME#parameters"
  },"5": {
    "doc": "DAME",
    "title": "Attributes",
    "content": "| Attribute Name | Type | Description | . | units_per_group | Array | This is an array of arrays. Each sub-array is a matched group, and each item in each sub-array is an int, indicating the unit in that matched group. If matching is done with repeats=False then no unit will appear more than once. If repeats=True then the first group in which a unit appears is its main matched group. | . | df_units_and_covars_matched | dataframe | This is the resulting matches of DAME. Each matched unit is in this array, and the covariates they were matched on have the value used to match. The covariates units were not matched on are indicated with a * | . | groups_per_unit | Array | The length of this is equal to the number of units in the input array. Each item in this array corresponds to the number of times that each item was matched. If matching is done with repeats=False, then this number will be either 0 or 1. | . | bf_each_iter | Array | if want_bf parameter is True, this will contain the balancing factor of the chosen covariate set at each iteration | . | pe_each_iter | Array | if want_pe parameter is True, this will contain the predictive error of the chosen covariate set at each iteration | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/DAME#attributes",
    "relUrl": "/documentation/api-documentation/DAME#attributes"
  },"6": {
    "doc": "DAME",
    "title": "Quick Example",
    "content": "import pandas as pd import dame_flame df = pd.read_csv(\"dame_flame/data/sample.csv\") model = dame_flame.matching.DAME(repeats=False, verbose=1, early_stop_iterations=False) model.fit(holdout_data=df) result = model.predict(input_data=df) print(result) #&gt; x1 x2 x3 x4 #&gt; 0 0 1 1 * #&gt; 1 0 1 1 * #&gt; 2 1 0 * 1 #&gt; 3 1 0 * 1 . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/DAME#quick-example",
    "relUrl": "/documentation/api-documentation/DAME#quick-example"
  },"7": {
    "doc": "DAME",
    "title": "Methods",
    "content": "| fit(self, holdout_data, treatment_col....) | Provide self with holdout data | . | predict(self, input_data...) | Perform the match on the input data | . __init__(adaptive_weights='ridge', alpha=0.1, repeats=True, verbose=2, early_stop_iterations=False, stop_unmatched_c=False, early_stop_un_c_frac=False, stop_unmatched_t=False, early_stop_un_t_frac=False, early_stop_pe=False, early_stop_pe_frac=0.01, early_stop_bf=False, early_stop_bf_frac=0.01, missing_indicator=np.nan, missing_data_replace=0, missing_holdout_replace=0, missing_holdout_imputations=10, missing_data_imputations=1, want_pe=False, want_bf=False) . Source Code . Initialize self . fit(self, holdout_data=False, treatment_column_name='treated', outcome_column_name='outcome' weight_array=False)) . Source Code . Provide self with holdout data . | fit Parameter Name | Type | Default | Description | . | holdout_data | {string, dataframe, float, False } | False | This is the holdout dataset. If a string is given, that should be the location of a CSV file to input. If a float between 0.0 and 1.0 is given, that corresponds the percent of the input dataset to randomly select for holdout data. If False, the holdout data is equal to the entire input data. | . | treatment_column_name | string | “treated” | This is the name of the column with a binary indicator for whether a row is a treatment or control unit. | . | outcome_column_name | string | “outcome” | This is the name of the column with the outcome variable of each unit. | . | adaptive_weights | {bool, “ridge”, “decision tree”, “ridgeCV”} | “ridge” | The method used to decide what covariate set should be dropped next. | . | weight_array | array | optional | If adaptive_weights = False, these are the weights to the covariates in input_data, for the non-adaptive version of DAME. Must sum to 1. In this case, we do not use machine learning for the weights, they are manually entered as weight_array. | . predict(self, input_data) . Source Code . Perform match and return matches . | predict Parameter Name | Type | Default | Description | . | input_data | {string, dataframe} | Required Parameter | The dataframe on which to perform the matching, or the location of the CSV with the dataframe | . | predict Return | Description | . | Result | Pandas dataframe of matched units and covariates matched on, with a “*” at each covariate that a unit did not use in matching | . Further Readings . Liu, Dieng, et al. Interpretable Almost Matching Exactly For Causal Inference. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/DAME#methods",
    "relUrl": "/documentation/api-documentation/DAME#methods"
  },"8": {
    "doc": "DAME",
    "title": "DAME",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/DAME",
    "relUrl": "/documentation/api-documentation/DAME"
  },"9": {
    "doc": "FLAME",
    "title": "dame_flame.matching.FLAME",
    "content": "The FLAME algorithm class . class dame_flame.matching.FLAME(adaptive_weights='ridge', alpha=0.1, repeats=True, verbose=2, early_stop_iterations=False, stop_unmatched_c=False, early_stop_un_c_frac=False, stop_unmatched_t=False, early_stop_un_t_frac=False, early_stop_pe=False, early_stop_pe_frac=0.01, early_stop_bf=False, early_stop_bf_frac=0.01, missing_indicator=np.nan, missing_data_replace=0, missing_holdout_replace=0, missing_holdout_imputations=10, missing_data_imputations=1, want_pe=False, want_bf=False) . Source Code . This class creates the matches based on the FLAME “Fast Large-Scale Almost Matching Exactly” algorithm. It has built in support for stopping criteria and missing data handling. Read more in the User Guide . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/FLAME#dame_flamematchingflame",
    "relUrl": "/documentation/api-documentation/FLAME#dame_flamematchingflame"
  },"10": {
    "doc": "FLAME",
    "title": "Parameters",
    "content": "| Parameter Name | Type | Default | Description | . | adaptive_weights | {bool, ‘ridge’, ‘decision tree’, ‘ridgeCV’} | ‘ridge’ | The method used to decide what covariate set should be dropped next. | . | alpha | float | 0.1 | If adaptive_weights is set to ridge, this is the alpha for ridge regression. | . | repeats | bool | True | Whether or not units for whom a main matched has been found can be used again, and placed in an auxiliary matched group. | . | verbose | int: {0,1,2,3} | 2 | Style of printout while algorithm runs. If 0, no output. If 1, provides iteration number. If 2, provides iteration number and additional information on the progress of the matching at every 10th iteration. If 3, provides iteration number and additional information on the progress of the matching at every iteration | . | early_stop_iterations | int | 0 | If provided, a number of iterations after which to hard stop the algorithm. | . | stop_unmatched_c | bool | False | If True, then the algorithm terminates when there are no more control units to match. | . | stop_unmatched_t | bool | False | If True, then the algorithm terminates when there are no more treatment units to match. | . | early_stop_un_c_frac | float | 0.1 | Must be between 0.0 and 1.0. This provides a fraction of unmatched control units. When the threshold is met, the algorithm will stop iterating. For example, using an input dataset with 100 control units, the algorithm will stop when 10 control units are unmatched and 90 are matched (or earlier, depending on other stopping conditions). | . | early_stop_un_t_frac | float | 0.1 | Must be between 0.0 and 1.0. This provides a fraction of unmatched treatment units. When the threshold is met, the algorithm will stop iterating. For example, using an input dataset with 100 treatment units, the algorithm will stop when 10 control units are unmatched and 90 are matched (or earlier, depending on other stopping conditions). | . | early_stop_pe | bool | False | If this is true, then if the covariate set chosen for matching has a predictive error higher than the parameter early_stop_pe_frac, the algorithm will stop. | . | early_stop_pe_frac | float | 0.01 | If early_stop_pe is true, then if the covariate set chosen for matching has a predictive error higher than this value, the algorithm will stop. | . | early_stop_bf | bool | False | If this is true, then if the covariate set chosen for matching has a balancing factor lower than early_stop_bf_frac, then the algorithm will stop. | . | early_stop_bf_frac | float | 0.01 | If early_stop_bf is true, then if the covariate set chosen for matching has a balancing factor lower than this value, then the algorithm will stop. | . | want_pe | bool | False | If true, the output of the algorithm will include the predictive error of the covariate sets used for matching in each iteration. | . | want_bf | bool | False | If true, the output will include the balancing factor for each iteration. | . | missing_indicator | {character, integer, numpy.nan} | numpy.nan | This is the indicator for missing data in the dataset. | . | missing_holdout_replace | int: {0,1,2} | 0 | If 0, assume no missing holdout data and proceed. If 1, the algorithm excludes units with missing values from the holdout dataset. If 2, do MICE on holdout dataset. If this option is selected, it will be done for a number of iterations equal to missing_holdout_imputations. | . | missing_data_replace | int: {0,1,2,3} | 0 | If 0, assume no missing data in matching data and proceed. If 1, the algorithm does not match on units that have missing values. If 2, prevent all missing_indicator values from being matched on. If 3, do MICE on matching dataset. This is not recommended. If this option is selected, it will be done for a number of iterations equal to missing_data_imputations. | . | missing_holdout_imputations | int | 10 | If missing_holdout_replace=2, the number of imputations. | . | missing_data_imputations | int | 1 | If missing_data_replace=3, the number of imputations. | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/FLAME#parameters",
    "relUrl": "/documentation/api-documentation/FLAME#parameters"
  },"11": {
    "doc": "FLAME",
    "title": "Attributes",
    "content": "| Attribute Name | Type | Description | . | units_per_group | Array | This is an array of arrays. Each sub-array is a matched group, and each item in each sub-array is an int, indicating the unit in that matched group. If matching is done with repeats=False then no unit will appear more than once. If repeats=True then the first group in which a unit appears is its main matched group. | . | df_units_and_covars_matched | dataframe | This is the resulting matches of FLAME. Each matched unit is in this array, and the covariates they were matched on have the value used to match. The covariates units were not matched on are indicated with a * | . | groups_per_unit | Array | The length of this is equal to the number of units in the input array. Each item in this array corresponds to the number of times that each item was matched. If matching is done with repeats=False, then this number will be either 0 or 1. | . | bf_each_iter | Array | if want_bf parameter is True, this will contain the balancing factor of the chosen covariate set at each iteration | . | pe_each_iter | Array | if want_pe parameter is True, this will contain the predictive error of the chosen covariate set at each iteration | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/FLAME#attributes",
    "relUrl": "/documentation/api-documentation/FLAME#attributes"
  },"12": {
    "doc": "FLAME",
    "title": "Quick Example",
    "content": "import pandas as pd import dame_flame df = pd.read_csv(\"dame_flame/data/sample.csv\") model = dame_flame.matching.FLAME(repeats=False, verbose=1, early_stop_iterations=False) model.fit(holdout_data=df) result = model.predict(input_data=df) print(result) #&gt; x1 x2 x3 x4 #&gt; 0 0 1 1 * #&gt; 1 0 1 1 * #&gt; 2 1 0 * 1 #&gt; 3 1 0 * 1 . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/FLAME#quick-example",
    "relUrl": "/documentation/api-documentation/FLAME#quick-example"
  },"13": {
    "doc": "FLAME",
    "title": "Methods",
    "content": "| fit(self, holdout_data, treatment_col....) | Provide self with holdout data | . | predict(self, input_data...) | Perform the match on the input data | . __init__(adaptive_weights='ridge', alpha=0.1, repeats=True, verbose=2, early_stop_iterations=False, stop_unmatched_c=False, early_stop_un_c_frac=False, stop_unmatched_t=False, early_stop_un_t_frac=False, early_stop_pe=False, early_stop_pe_frac=0.01, early_stop_bf=False, early_stop_bf_frac=0.01, missing_indicator=np.nan, missing_data_replace=0, missing_holdout_replace=0, missing_holdout_imputations=10, missing_data_imputations=1, want_pe=False, want_bf=False) . Source Code . Initialize self . fit(self, holdout_data=False, treatment_column_name='treated', outcome_column_name='outcome' weight_array=False)) . Source Code . Provide self with holdout data . | fit Parameter Name | Type | Default | Description | . | holdout_data | {string, dataframe, float, False } | False | This is the holdout dataset. If a string is given, that should be the location of a CSV file to input. If a float between 0.0 and 1.0 is given, that corresponds the percent of the input dataset to randomly select for holdout data. If False, the holdout data is equal to the entire input data. | . | treatment_column_name | string | “treated” | This is the name of the column with a binary indicator for whether a row is a treatment or control unit. | . | outcome_column_name | string | “outcome” | This is the name of the column with the outcome variable of each unit. | . | adaptive_weights | {bool, “ridge”, “decision tree”, “ridgeCV”} | “ridge” | The method used to decide what covariate set should be dropped next. | . | weight_array | array | optional | If adaptive_weights = False, these are the weights to the covariates in input_data, for the non-adaptive version of FLAME. Must sum to 1. In this case, we do not use machine learning for the weights, they are manually entered as weight_array. | . predict(self, input_data) . Source Code . Perform match and return matches . | predict Parameter Name | Type | Default | Description | . | input_data | {string, dataframe} | Required Parameter | The dataframe on which to perform the matching, or the location of the CSV with the dataframe | . | C | float | 0.1 | The tradeoff parameter between the balancing factor and the predictive error when deciding which covariates to match on | . | pre_dame | {bool, integer} | False | If an integer is provided, this is the number of iterations to run the FLAME algorithm for before switching to DAME, in order for a hybrid FLAME-DAME option. | . | predict Return | Description | . | Result | Pandas dataframe of matched units and covariates matched on, with a “*” at each covariate that a unit did not use in matching | . Further Readings . Wang, Morucci, et al. FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/FLAME#methods",
    "relUrl": "/documentation/api-documentation/FLAME#methods"
  },"14": {
    "doc": "FLAME",
    "title": "FLAME",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/FLAME",
    "relUrl": "/documentation/api-documentation/FLAME"
  },"15": {
    "doc": "API Documentation",
    "title": "API Documentation",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/",
    "relUrl": "/documentation/api-documentation/"
  },"16": {
    "doc": "ATE",
    "title": "dame_flame.utils.post_processing.ATE",
    "content": "The average treatment effect estimate of the data . ATE(matching_object) . Source Code . Uses the matches created by the FLAME and DAME algorithms to provide ATE of the dataset. Read more about Average Treatment Effect (ATE) in the User Guide . | Parameter Name | Type | Description | . | matching_object | {dame_flame.matching.DAME, dame_flame.matching.FLAME} | The matching object used to run DAME and FLAME. This must be after the .fit() and .predict() methods have been called to create the matches. | . | Return Name | Type | Description | . | ATE | {float, np.nan} | A float representing the ATE of the dataset. If no units were matched, then the output will be np.nan. | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/ATE#dame_flameutilspost_processingate",
    "relUrl": "/documentation/api-documentation/ATE#dame_flameutilspost_processingate"
  },"17": {
    "doc": "ATE",
    "title": "Quick Example",
    "content": "import pandas as pd import dame_flame df = pd.read_csv(\"dame_flame/data/sample.csv\") model = dame_flame.matching.FLAME(repeats=False, verbose=1, early_stop_iterations=False) model.fit(holdout_data=df) result = model.predict(input_data=df) print(result) #&gt; x1 x2 x3 x4 #&gt; 0 0 1 1 * #&gt; 1 0 1 1 * #&gt; 2 1 0 * 1 #&gt; 3 1 0 * 1 . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/ATE#quick-example",
    "relUrl": "/documentation/api-documentation/ATE#quick-example"
  },"18": {
    "doc": "ATE",
    "title": "ATE",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/ATE",
    "relUrl": "/documentation/api-documentation/ATE"
  },"19": {
    "doc": "ATT",
    "title": "dame_flame.utils.post_processing.ATT",
    "content": "The average treatment effect estimate on the treated units in the data . ATT(matching_object) . Source Code . Uses the matches created by the FLAME and DAME algorithms to provide ATT of the dataset. Read more about Average Treatment Effect on treated units (ATT) in the User Guide . | Parameter Name | Type | Description | . | matching_object | {dame_flame.matching.DAME, dame_flame.matching.FLAME} | The matching object used to run DAME and FLAME. This must be after the .fit() and .predict() methods have been called to create the matches. | . | Return Name | Type | Description | . | ATT | {float, np.nan} | A float representing the ATT of the dataset. If no units were matched, then the output will be np.nan. | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/ATT#dame_flameutilspost_processingatt",
    "relUrl": "/documentation/api-documentation/ATT#dame_flameutilspost_processingatt"
  },"20": {
    "doc": "ATT",
    "title": "Quick Example",
    "content": "import pandas as pd import dame_flame df = pd.read_csv(\"dame_flame/data/sample.csv\") model = dame_flame.matching.FLAME(repeats=False, verbose=1, early_stop_iterations=False) model.fit(holdout_data=df) result = model.predict(input_data=df) print(result) #&gt; x1 x2 x3 x4 #&gt; 0 0 1 1 * #&gt; 1 0 1 1 * #&gt; 2 1 0 * 1 #&gt; 3 1 0 * 1 . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/ATT#quick-example",
    "relUrl": "/documentation/api-documentation/ATT#quick-example"
  },"21": {
    "doc": "ATT",
    "title": "ATT",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/ATT",
    "relUrl": "/documentation/api-documentation/ATT"
  },"22": {
    "doc": "CATE",
    "title": "dame_flame.utils.post_processing.CATE",
    "content": "The conditional average treatment effect estimate of a subset of the data . CATE(matching_object, unit_ids) . Source Code . Uses the matches created by the FLAME and DAME algorithms to provide CATE of subsets of the dataset. Read more about Conditional Average Treatment Effect (CATE) estimates in the User Guide . | Parameter Name | Type | Description | . | matching_object | {dame_flame.matching.DAME, dame_flame.matching.FLAME} | The matching object used to run DAME and FLAME, after the .fit() and .predict() methods have been called to create the matches. If the matching_object’s parameter for verbose is not 0, then as units without matches appear, the function will print this. | . | unit_ids | {int, list} | A unit id or list of unit ids | . | Return Name | Type | Description | . | MMGs | {list, float, np.nan} | If one unit id was provided, this is a single float representing the conditional average treatment effect of the unit. This is equal to the CATE of the group that the unit is in. If the unit does not have a match, the return will be np.nan. If multiple unit ids were provided, this will be a list of floats with the CATE of each unit provided. If any unit does not have a match, rather than a float within the list, at its place will be np.nan. | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/CATE#dame_flameutilspost_processingcate",
    "relUrl": "/documentation/api-documentation/CATE#dame_flameutilspost_processingcate"
  },"23": {
    "doc": "CATE",
    "title": "Quick Example",
    "content": "import pandas as pd import dame_flame df = pd.read_csv(\"dame_flame/data/sample.csv\") model = dame_flame.matching.FLAME(repeats=False, verbose=1, early_stop_iterations=False) model.fit(holdout_data=df) result = model.predict(input_data=df) print(result) #&gt; x1 x2 x3 x4 #&gt; 0 0 1 1 * #&gt; 1 0 1 1 * #&gt; 2 1 0 * 1 #&gt; 3 1 0 * 1 . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/CATE#quick-example",
    "relUrl": "/documentation/api-documentation/CATE#quick-example"
  },"24": {
    "doc": "CATE",
    "title": "CATE",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/CATE",
    "relUrl": "/documentation/api-documentation/CATE"
  },"25": {
    "doc": "Matched Group",
    "title": "dame_flame.utils.post_processing.MG",
    "content": "The matched group of a unit . MG(matching_object, unit_ids, output_style=1) . Source Code . Uses the matches created by the FLAME and DAME algorithms to provide main matched groups of units. Read more about matched groups in the User Guide . | Parameter Name | Type | Description | . | matching_object | {dame_flame.matching.DAME, dame_flame.matching.FLAME} | The matching object used to run DAME and FLAME, after the .fit() and .predict() methods have been called to create the matches. If the matching_object’s parameter for verbose is not 0, then as units without matches appear, the function will print this. | . | unit_ids | {int, list} | A unit id or list of unit ids | . | output_style | int: {0,1} (default=1) | If 1, the covariates which were not used in matching for the group of the unit will have a “*” rather than the covariate value. Otherwise, it will output all covariate values. | . | Return Name | Type | Description | . | MMGs | {list, dataframe, np.nan} | If one unit id was provided, this is a single dataframe containing the main matched group of the unit. If the unit does not have a match, the return will be np.nan. If multiple unit ids were provided, this will be a list of dataframes with the main matched group of each unit provided. If any unit does not have a match, rather than a dataframe, at its place will be np.nan. | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/matched-group#dame_flameutilspost_processingmg",
    "relUrl": "/documentation/api-documentation/matched-group#dame_flameutilspost_processingmg"
  },"26": {
    "doc": "Matched Group",
    "title": "Quick Example",
    "content": "import pandas as pd import dame_flame df = pd.read_csv(\"dame_flame/data/sample.csv\") model = dame_flame.matching.FLAME(repeats=False, verbose=1, early_stop_iterations=False) model.fit(holdout_data=df) result = model.predict(input_data=df) print(result) #&gt; x1 x2 x3 x4 #&gt; 0 0 1 1 * #&gt; 1 0 1 1 * #&gt; 2 1 0 * 1 #&gt; 3 1 0 * 1 . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/matched-group#quick-example",
    "relUrl": "/documentation/api-documentation/matched-group#quick-example"
  },"27": {
    "doc": "Matched Group",
    "title": "Matched Group",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/api-documentation/matched-group",
    "relUrl": "/documentation/api-documentation/matched-group"
  },"28": {
    "doc": "Documentation",
    "title": "Documentation",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation",
    "relUrl": "/documentation"
  },"29": {
    "doc": "Benefit to Early Stopping",
    "title": "Early Stopping and Treatment Effect Estimates",
    "content": "Both the FLAME and DAME algorithms begin by matching identical twins (“exact matches”) in the dataset. As iterations of the algorithm progress, later matched units are likely to have the highest error in estimated treatment effects. For this reason, there are situations where a user may wish to stop the FLAME or DAME algorithm in order to avoid poor quality matches, and if its not critical that all units are matched. From this example, we see that if high accuraccy between the estimated treatment effect and true treatment effect is a priority, then this algorithm should be stopped early. import numpy as np import pandas as pd import dame_flame import matplotlib.pyplot as plt from sklearn.metrics import mean_squared_error def draw_scatter(ax, x, y, title, color, mse, yticks= False): ax.scatter(x, y, c = color, alpha = 0.3, marker = 'o', edgecolor = 'black') ax.set_title(title, pad = 0.2, wrap = True, fontsize=labelsize*.75) ax.tick_params(labelsize=ticksize) ax.set_ylabel(\"Estimated CATT\", fontsize = labelsize*.75) ax.text(1, 35, \"MSE: {:.2f}\".format(mse), ha='center', va='center', fontsize=labelsize*.75) ax.set_xlabel('True CATT') # Generate Data df, true_catt = dame_flame.utils.data.gen_data_binx_decay_importance(num_control=1000, num_treated=1000, num_cov=10, bernoulli_param=0.5, bi_mean=2, bi_stdev=1) # Get Matches using the DAME algorithm model = dame_flame.matching.DAME(repeats=False, verbose=0) model.fit(holdout_data=df) model.predict(df) model_stop_early = dame_flame.matching.DAME(repeats=False, verbose=0, early_stop_un_c_frac=0.3) model_stop_early.fit(holdout_data=df) model_stop_early.predict(df) # Since not all units are matched, filter on those that are when finding CATT estimated_catt_full = [] true_catt_full = [] estimated_catt_early = [] true_catt_early = [] for unit in range(len(df)): if df.loc[unit]['treated'] == 1: temp_cate = dame_flame.utils.post_processing.CATE(model, unit) if temp_cate is not np.nan: estimated_catt_full.append(temp_cate) true_catt_full.append(true_catt[unit]) temp_cate = dame_flame.utils.post_processing.CATE(model_stop_early, unit) if temp_cate is not np.nan: estimated_catt_early.append(temp_cate) true_catt_early.append(true_catt[unit]) # Draw plot draw_scatter(axes[0], true_catt_early, estimated_catt_early, \"DAME, stopped at 30% control unmatched\", \"green\", mean_squared_error(true_catt_early, estimated_catt_early), True) draw_scatter(axes[1], true_catt_full, estimated_catt_full, \"DAME, matching all units\", \"green\", mean_squared_error(true_catt_full, estimated_catt_full), True) . Download Example From GitHub . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/examples/early_stopping/#early-stopping-and-treatment-effect-estimates",
    "relUrl": "/examples/early_stopping/#early-stopping-and-treatment-effect-estimates"
  },"30": {
    "doc": "Benefit to Early Stopping",
    "title": "Benefit to Early Stopping",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/examples/early_stopping/",
    "relUrl": "/examples/early_stopping/"
  },"31": {
    "doc": "Exact Matching Only",
    "title": "Exact Matching",
    "content": "The DAME or FLAME algorithm can be configured to be used for exact matching, using the early stopping criteria parameter early_stop_iterations=1. We illustrate this below. On a dataset with 200 units and five covariates that was generated with little randomness in which most covariate values are the same, we are only interested in exactly matched units. The output generated by the verbose=3 parameter shows that the majority of units are matched after one iteration. We visualize the treatment effect of each group, or the CATE of each group, using matplotlib [1]. We also visualize the matched groups’ sizes, which shows that one group has the majority of units. import dame_flame import matplotlib.pyplot as plt df,_ = dame_flame.utils.data.gen_data_decay_importance(num_control=100, num_treated=100, num_cov=5, bernoulli_param=0.9, bi_mean=2, bi_stdev=1) model = dame_flame.matching.FLAME(verbose=3, early_stop_iterations=1) model.fit(holdout_data=df) res = model.predict(df) groups = list(range(len(model.units_per_group))) cate_of_group = [] len_group = [] for group in model.units_per_group: cate_of_group.append(dame_flame.utils.post_processing.CATE(model, group[0])) len_group.append(len(group)) f, ax = plt.subplots(1, 2, gridspec_kw = {'width_ratios':[1, 1]}, figsize=(12,4)) ax[0].set_ylabel('Treatment Effect of Group', fontsize=14) ax[0].set_xlabel('Matched group ID number', fontsize=14) ax[0].set_title('Treatment Effect of Each Group of Perfectly Matched Units', fontsize=14) ax[0].bar(groups,cate_of_group) ax[1].set_ylabel('Number of Units in Group', fontsize=14) ax[1].set_xlabel('Matched group ID number', fontsize=14) ax[1].set_title('Size of Each Group of Perfectly Matched Units', fontsize=14) ax[1].bar(groups,len_group) plt.tight_layout() plt.savefig('treatment_effect_size_of_groups.png') . Download Example From GitHub . References . [1] Matplotlib: Grouped bar chart with labels ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/examples/exact_matching/#exact-matching",
    "relUrl": "/examples/exact_matching/#exact-matching"
  },"32": {
    "doc": "Exact Matching Only",
    "title": "Exact Matching Only",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/examples/exact_matching/",
    "relUrl": "/examples/exact_matching/"
  },"33": {
    "doc": "Examples",
    "title": "Examples",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/examples",
    "relUrl": "/examples"
  },"34": {
    "doc": "Comparing DAME and FLAME",
    "title": "Comparing Match Quality of DAME and FLAME",
    "content": "Both the FLAME and DAME algorithms begin by matching any possible identical twins (“exact matches”) in the dataset, meaning any units that have the same values on every possible covariate. As the FLAME algorithm progresses to match units that do not have identical twins, each subsequent iteration of the FLAME algorithm will attempt to match on one fewer covariate. So, suppose the total number of covariates in a dataset is $r$. After any units that can be exact matched on $r$ have been found, the next iteration of FLAME will attempt to match on $r-1$ covariates. In the next iteration, it improves upon the previous covariate set used for matching, and match on $r-2$ covariates. However, DAME will consider any covariate set options that will yield the highest-quality matches. The size of covariates matched on does not necessarily need to decrease over iterations of the algorithm. This one of the key advantages the DAME algorithm has over FLAME. DAME produces higher quality matches, meaning that more units are matched on a large number of covariates. We show this below using matplotlib [1], running the same dataset on FLAME and DAME for 10 iterations. import numpy as np import pandas as pd import dame_flame import matplotlib.pyplot as plt # Generate Data num_covariates = 10 df, true_catt = dame_flame.utils.data.gen_data_binx_decay_importance(num_control=1000, num_treated=1000, num_cov=num_covariates, bernoulli_param=0.5, bi_mean=2, bi_stdev=1) # Get matches using DAME and FLAME model_dame = dame_flame.matching.DAME(repeats=False, verbose=0, early_stop_iterations=10) model_dame.fit(holdout_data=df) result_dame = model_dame.predict(df) model_flame = dame_flame.matching.FLAME(repeats=False, verbose=0, early_stop_iterations=10) model_flame.fit(holdout_data=df) result_flame = model_flame.predict(df) # pre-processing result_flame = result_flame.replace(to_replace='*', value=np.nan) result_dame = result_dame.replace(to_replace='*', value=np.nan) dict_matched_result_dame = {k:0 for k in range(0,num_covariates+1)} dict_matched_result_flame = {k:0 for k in range(0,num_covariates+1)} for i in result_flame.count(axis=1): dict_matched_result_flame[i] += 1 for i in result_dame.count(axis=1): dict_matched_result_dame[i] += 1 # plot x = np.arange(len(dict_matched_result_flame.keys())) # the label locations width = 0.5 # the width of the bars f, ax = plt.subplots(figsize=(12,9)) rects1 = ax.bar(x - width/2, dict_matched_result_flame.values(), width, color=\"green\", label = \"DAME\" ) #, stopping at {}% control units matched\".format(percent), hatch=\"/\") rects2 = ax.bar(x + width/2, dict_matched_result_dame.values(), width, color = \"orange\", label = \"FLAME\") #, stopping at {}% control units matched\".format(percent), hatch = \"\\\\\") ax.set_ylabel('Number of units', fontsize=16) ax.set_xlabel('Number of covariates matched on', fontsize=16) ax.set_title('Number of covariates that units were matched on after 10 iterations', fontsize=16) ax.set_xticks(x) ax.set_xticklabels(dict_matched_result_flame.keys()) ax.legend(fontsize=16) def autolabel(rects): \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\" for rect in rects: height = rect.get_height() ax.annotate('{}'.format(height), xy=(rect.get_x() + rect.get_width() / 2, height), xytext=(0, 3), # 3 points vertical offset textcoords=\"offset points\", ha='center', va='bottom') autolabel(rects1) autolabel(rects2) plt.show() . Download Example From GitHub . References . [1] Matplotlib: Grouped bar chart with labels ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/examples/flame_vs_dame_quality/#comparing-match-quality-of-dame-and-flame",
    "relUrl": "/examples/flame_vs_dame_quality/#comparing-match-quality-of-dame-and-flame"
  },"35": {
    "doc": "Comparing DAME and FLAME",
    "title": "Comparing DAME and FLAME",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/examples/flame_vs_dame_quality/",
    "relUrl": "/examples/flame_vs_dame_quality/"
  },"36": {
    "doc": "Interpreting Covariate Importance",
    "title": "Interpreting Covariate Importance",
    "content": "DAME-FLAME is an interpretable matching package because it allows users to quickly and easily understand which covariates were selected to be important to their outcome. This can be useful in determining who benefits from treatment the most and where resources should be spent for future treatment. In this example, using the verbose==3 option, we show how to view the iterations of the algorithm and infer the best covariates. We begin with a simulated dataset in which four covariates are labelled 0 to 3, and the covariates are of exponentially decreasing importance to the outcome as the label number increases. We see from the output that the FLAME algorithm drops unimportant covariates earlier in its algorithm. At each iteration of the FLAME algorithm, FLAME drops the least important covariate. In this example, we also graph the number of units that were placed in a matched group based on each covariate. You can see that most units were matched using the most important covariate, and the least important covariate is used in comparatively fewer matches. import numpy as np import dame_flame import matplotlib.pyplot as plt # Generate Data df, true_catt = dame_flame.utils.data.generate_uniform_given_importance(50,50) # Get matches using DAME and FLAME model_dame = dame_flame.matching.DAME(repeats=False) model_dame.fit(holdout_data=df) result_dame = model_dame.predict(df) model_flame = dame_flame.matching.FLAME(repeats=False, verbose=3) model_flame.fit(holdout_data=df) result_flame = model_flame.predict(df) . # replace all the '*'s with NAs so we can get a count of the NAs. result_flame = result_flame.replace(to_replace='*', value=np.nan) result_dame = result_dame.replace(to_replace='*', value=np.nan) # rename columns for graph X_columns = [\"X\" + col for col in result_flame.columns] result_flame.columns = X_columns result_dame.columns = X_columns x = np.arange(len(result_flame.columns)) # the label locations width = 0.35 # the width of the bars f, ax = plt.subplots(figsize=(12,9)) rects1 = ax.bar(x - width/2, result_dame.count(axis=0), width, color=\"lightcoral\", label = \"DAME\" ) #, stopping at {}% control units matched\".format(percent), hatch=\"/\") rects2 = ax.bar(x + width/2, result_flame.count(axis=0), width, color = \"darkorchid\", label = \"FLAME\") #, stopping at {}% control units matched\".format(percent), hatch = \"\\\\\") ax.set_ylabel('Number of units matched on covariate', fontsize=16) ax.set_xlabel('Covariate name', fontsize=16) ax.set_title('Covariate Importance, measured by number of units matched on each covariate', fontsize=16) ax.set_xticks(x) ax.set_xticklabels(result_flame.columns) ax.legend(fontsize=16) def autolabel(rects): \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\" for rect in rects: height = rect.get_height() ax.annotate('{}'.format(height), xy=(rect.get_x() + rect.get_width() / 2, height), xytext=(0, 3), # 3 points vertical offset textcoords=\"offset points\", ha='center', va='bottom') autolabel(rects1) autolabel(rects2) f.tight_layout() plt.savefig('covariate_importance.png') . Download Example From GitHub . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/examples/interpretability/",
    "relUrl": "/examples/interpretability/"
  },"37": {
    "doc": "Algorithm Controls",
    "title": "Early Stopping Controls",
    "content": ". | Introduction to Early Stopping Controls | Recommendations | . This goes in the Algorithm Controls page. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Algorithm-Controls#early-stopping-controls",
    "relUrl": "/documentation/user-guide/Algorithm-Controls#early-stopping-controls"
  },"38": {
    "doc": "Algorithm Controls",
    "title": "Introduction to Early Stopping Controls",
    "content": "The ideal situation for matching in causal inference is if each treatment unit has an exactly identical control unit. We can best determine the rise in income that a person experiences after a job training program if that person has an identical twin with the same degree and GPA as them who didn’t attend the job training program. The FLAME-DAME package begins by matching identical twins (“exact matches”) in the dataset. Since not all units have exact matches, most units are matched based on subsets of all covariates. The subset that a unit is matched on is the subsets that is selected to be most predictive of their outcome. As the FLAME and DAME algorithms run, the units that are matched later in the algorithm, are those that are most distinct in observable characteristics from the other units in the dataset are matched later. Later matched units are likely to have the highest error in estimated treatment effects. For this reason, there are situations where the FLAME or DAME algorithm should be stopped early in order to avoid poor matches. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Algorithm-Controls#introduction-to-early-stopping-controls",
    "relUrl": "/documentation/user-guide/Algorithm-Controls#introduction-to-early-stopping-controls"
  },"39": {
    "doc": "Algorithm Controls",
    "title": "Recommendations",
    "content": "The default option is that the algorithm runs until all units are matched. However, if runtime or high accuracy of estimates of treatment effects are important, then we recommend users experiment with their stopping criteria based on their specific need and dataset size. A large dataset will have a longer runtime, and an early stop will take less time. Regardless of the early stopping criteria chosen, in the majority of datasets, any early stopping will lead to closer estimates between the estimated and true treatment effects. This is illustrated in the examples section. If it is crucial that all units be matched, it is recommended that users do not use any early stopping criteria. | Category of Early Stopping | Technical Details | Usage Recommendation | Algorithm parameters | . | Algorithm Iterations | This provides a number of iterations after which to stop the DAME or FLAME algorithm. If FLAME is used, then this is the maximum number of covariates that can be dropped, meaning when the total number of covariates is $m$, no unit will be matched on $m-$early_stop_iterations covariates | This is useful in the case of a FLAME user knowing their preferred covariate match size, or if a user knows what runtime is sufficient from a previous experiment | early_stop_iterations | . | Unmatched Units in Treatment or Control | When the algorithm is set with the repeats=True parameter, then previously matched units can still be placed in groups with other units. The algorithm will by default stop iterating when there are no more units that have not been placed in any group. However, a case could arise where all units remaining to be placed in a group are of the treatment or control group, and we provide this option in case a user has preference between ensuring that all treated or control units are matched. | These parameters will not be useful, and is therefore not recommended in the case where the the repeats parameter is False. If repeats=False, then in effect, both of these parameters are True. | stop_unmatched_c, stop_unmatched_t | . | Proportion of unmatched units | This stops the algorithm when some fraction of control units or treatment units are unmatched | One specific case in which this could be useful immediately is where a user is certain that some percent of the input is unlikely to result in good matches. | early_stop_un_c_frac, early_stop_un_t_frac | . | Predictive Error | The predictive error measures how important a covariate set is for predicting the outcome on the holdout dataset, using a machine learning algorithm. It is the sole determinant of the covariate set to match on for DAME, and one of two factors for FLAME. | The range of this value is specific to a dataset’s values. Therefore, reasonable values for this can only be determined after at least one prior run of this algorithm on the same dataset in which the predictive error is observed. | early_stop_pe, early_stop_pe_frac | . | Balancing Factor | The balancing factor of an iteration is the number of matches formed after selecting a covariate set, and the discrepancy between the number of treated and control units remaining to be matched after the matching. This is only part of the algorithm’s decision of which covariates to drop for FLAME but is still measured for DAME. | If it’s important to a user that there be a balance between treatment and control units in each covariate set, this is a parameter to pay attention to. The range of this value is specific to a dataset’s values. Therefore, reasonable values for this can only be determined after at least one prior run of this algorithm on the same dataset, while observing the balancing factor. | early_stop_bf, early_stop_bf_frac | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Algorithm-Controls#recommendations",
    "relUrl": "/documentation/user-guide/Algorithm-Controls#recommendations"
  },"40": {
    "doc": "Algorithm Controls",
    "title": "Algorithm Controls",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Algorithm-Controls",
    "relUrl": "/documentation/user-guide/Algorithm-Controls"
  },"41": {
    "doc": "Getting Matches",
    "title": "Getting Matches from the Data",
    "content": ". | FLAME | DAME | Variations in the learning of the best covariate set | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Getting-Matches#getting-matches-from-the-data",
    "relUrl": "/documentation/user-guide/Getting-Matches#getting-matches-from-the-data"
  },"42": {
    "doc": "Getting Matches",
    "title": "FLAME",
    "content": "FLAME stands for Fast Large Scale Almost Matching Exactly. The FLAME algorithm begins by matching any units that can be matched exactly on all covariates. The algorithm will iterate over all covariates until stopping criteria is reached. In each iteration, the algorithm will drop the worst covariate set to match on, and units that have identical values in all of the remaining covariates will form a matched group. When deciding which covariate should be dropped, at each step, it drops the covariate leading to the smallest drop in match quality, MQ, defined as MQ=C·BF−PE. Here, PE denotes the predictive error, which measures how important the dropped covariate is for predicting the outcome on the holdout dataset, using a machine learning algorithm. The balancing factor, BF, measures the number of matches formed by dropping that covariate and the discrepancy between the number of treated and control units after the matching. In future iterations, the covariate that was determined worst and was just dropped will not reappear, so the maximum number of times the algorithm will iterate is equal to the number of covariates. For more details on this algorithm, see [1]. import pandas as pd import dame_flame df = pd.read_csv(\"dame_flame/data/sample.csv\") model = dame_flame.matching.FLAME(repeats=False, verbose=1, early_stop_iterations=False) model.fit(holdout_data=df) result = model.predict(input_data=df) print(result) #&gt; x1 x2 x3 x4 #&gt; 0 0 1 1 * #&gt; 1 0 1 1 * #&gt; 2 1 0 * 1 #&gt; 3 1 0 * 1 . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Getting-Matches#flame",
    "relUrl": "/documentation/user-guide/Getting-Matches#flame"
  },"43": {
    "doc": "Getting Matches",
    "title": "DAME",
    "content": "DAME stands for Dynamic Almost Matching Exactly. The algorithm begins by matching any units that can be matched exactly on all co-variates. The algorithm will iterate over options of covariates to match on until stopping criteria is reached. In each iteration, the algorithm will select the best covariate set to match on, and units that have identical values in all of the covariates that are part of the chosen covariate set will form a matched group. In its options of covariate sets to drop, DAME will always include the largest possible covariate sets, and will ultimately consider several combinations of covariates before selecting one to match on. It defines the best covariate set as the one that minimizes PE. PE is predictive error, and measures how important the covariate set is for predicting the outcome on the holdout dataset, using a machine learning algorithm. For more details on this algorithm, see [2]. import pandas as pd import dame_flame df = pd.read_csv(\"dame_flame/data/sample.csv\") model = dame_flame.matching.DAME(repeats=False, verbose=1, early_stop_iterations=False) model.fit(holdout_data=df) result = model.predict(input_data=df) print(result) #&gt; x1 x2 x3 x4 #&gt; 0 0 1 1 * #&gt; 1 0 1 1 * #&gt; 2 1 0 * 1 #&gt; 3 1 0 * 1 . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Getting-Matches#dame",
    "relUrl": "/documentation/user-guide/Getting-Matches#dame"
  },"44": {
    "doc": "Getting Matches",
    "title": "Variations in the learning of the best covariate set",
    "content": "Both the FLAME and DAME algorithms choose the best covariate set after measuring how important each covariate set is for predicting the outcome on the holdout dataset, using a machine learning algorithm. We offer different options for the machine learning algorithm used, as well as a simplified FLAME and simplified DAME that does not use machine learning. We use scikit-learn for the underlying learning algorithms, so we refer you to their documentation and references to learn more about these popular machine learning algorithms, as well as their specific implementations. For examples of categorical, binary, and numerical data, see [3]. | Learning Method | Technical Details | Usage Recommendation | Algorithm parameter | . | Ridge Regression | A ridge regression is similar to an ordinary least squares regression, but it imposes a penalty on the size of coefficients. It minimizes a residual sum of squares. A shrinkage parameter, $\\alpha$ must be included. We use an implementation provided by scikit-learn [4]. | This can only be used when it is certain that none of the covariates are categorical. Ordinal, binary, and discrete numerical data is all accepted. For this option, a larger $\\alpha$ corresponds should be chosen if it is believed that there is greater multicollinearity in the data, meaning that many covariates are linearly correlated. | adaptive_weights='ridge' | . | Ridge Regression CV | This is a ridge regression with built-in cross validation to determine the best $\\alpha$ parameter. We use the scikit-learn ridgeCV class, but the default array of $\\alpha$ options that we provide the function to iterate over is larger than the default they provide, for greater flexibility [5]. | This also can only be used when it is certain that none of the covariates are categorical. Ordinal, binary and discrete numerical data is all accepted. This option is advantageous over the ‘ridge’ option without cross validation in a case where a user is uncertain about the $\\alpha$ parameter, and a minor speed decrease from cross validation is acceptable. | adaptive_weights='ridgeCV' | . | Decision Tree | The underlying implementation is the Decision Tree Regression provided by scikit-learn, which uses a variation of CART [6]. Trees predict the value of the outcome by learning decision rules from the covariates. | This can be used for categorical, ordinal, binary, and discrete numerical data. Overfitting is a risk with decision tree models, which can be possible in DAME or FLAME algorithm if the holdout and input datasets provided are the same. | adaptive_weights='decision-tree' | . References . [1] Wang, Morucci, et al. FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference. [2] Liu, Dieng, et al. Interpretable Almost Matching Exactly For Causal Inference. [3] What is the Difference Between Categorical, Ordinal, and Numerical Variables? UCLA: Statistical Consulting Group. [4] Scikit-learn Ridge Regressions [5] Scikit-learn RidgeCV [6] Scikit-learn DecisionTree ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Getting-Matches#variations-in-the-learning-of-the-best-covariate-set",
    "relUrl": "/documentation/user-guide/Getting-Matches#variations-in-the-learning-of-the-best-covariate-set"
  },"45": {
    "doc": "Getting Matches",
    "title": "Getting Matches",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Getting-Matches",
    "relUrl": "/documentation/user-guide/Getting-Matches"
  },"46": {
    "doc": "Discrete Observation Requirement",
    "title": "DAME-FLAME Data Requirements",
    "content": ". | Discrete Observation Requirement for DAME-FLAME | Example of Acceptable Binning | Input Format Example | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/data-requirements#dame-flame-data-requirements",
    "relUrl": "/documentation/user-guide/data-requirements#dame-flame-data-requirements"
  },"47": {
    "doc": "Discrete Observation Requirement",
    "title": "Discrete Observation Requirement for DAME-FLAME",
    "content": "The main requirements for researchers to justify the use of matching methods also hold for DAME-FLAME. Those are discussed here. In sum, we require SUTVA, ignorability, and some overlap. Additionally, we require that all observational covariates be discrete. The outcome data can be continuous. The treatment indicator column must be binary. We do not recommend users bin continous covariates. The only exception that could be made is a scenario where users are confident they are binning variables in a way that is a typical for their research. In this scenario, categories must be pre-defined and considered acceptable in their domain of work. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/data-requirements#discrete-observation-requirement-for-dame-flame",
    "relUrl": "/documentation/user-guide/data-requirements#discrete-observation-requirement-for-dame-flame"
  },"48": {
    "doc": "Discrete Observation Requirement",
    "title": "Example of Acceptable Binning",
    "content": "In research incorporating infant births, gestation time could be binned and used in DAME-FLAME as an observational covariate. Classifications of gestational age are well established norms adhered to in obstetric publications. Early term is considered 37 0/7 weeks of gestation through 38 6/7 weeks of gestation, full term is 39 0/7 weeks of gestation through 40 6/7 weeks of gestation, etc. The American College of Obstetricians and Gynecologists and the Society for Maternal-Fetal Medicine endorse and encourage these categories [1]. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/data-requirements#example-of-acceptable-binning",
    "relUrl": "/documentation/user-guide/data-requirements#example-of-acceptable-binning"
  },"49": {
    "doc": "Discrete Observation Requirement",
    "title": "Input Format Example",
    "content": "Below, we provide an example of the format that the DAME-FLAME package requires input data to be in. The input data can be either a file, or a Python Pandas Data Frame. All covariates in the input data should be categorical covariates. If there are continuous covariates, we only recommend users regroup the data if they are sure they are doing so in a way that is typical of their research question. In addition to input observational data columns, the input data must contain (1) A column indicating the outcome variable as an integer or float data type, and (2) A column specifying whether a unit is treated or control (treated = 1, control = 0) as an integer data type. There are no requirements for input data column names or order of columns. Below is an example of input data with n units and m covariates. | Column-name / unit-id | x_1 | x_2 | … | x_m | outcome | treated | . | 1 | 2 | 3 | … | 4 | 9 | 0 | . | 2 | 1 | 3 | … | 3 | 5.5 | 1 | . | 3 | 1 | 4 | … | 5 | -1 | 0 | . | … | … | … | … | … | … | … | . | n | 0 | 5 | … | 0 | 1 | 1 | . | Data Type | integer | integer | integer | integer | numeric | 0 or 1 | . The holdout training set, if provided, should also follow the same format. References . [1] ACOG Committee Opinion No 579: Definition of Term Pregnancy ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/data-requirements#input-format-example",
    "relUrl": "/documentation/user-guide/data-requirements#input-format-example"
  },"50": {
    "doc": "Discrete Observation Requirement",
    "title": "Discrete Observation Requirement",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/data-requirements",
    "relUrl": "/documentation/user-guide/data-requirements"
  },"51": {
    "doc": "Introduction to Causal Inference",
    "title": "Introduction",
    "content": ". | Introduction to Causal Inference | Introduction to Matching | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Introduction#introduction",
    "relUrl": "/documentation/user-guide/Introduction#introduction"
  },"52": {
    "doc": "Introduction to Causal Inference",
    "title": "Introduction to Causal Inference",
    "content": "Causal inference is the attempt to draw conclusions that something is being caused by something else. It goes beyond questions of correlation, association, and is distinct from model-based predictive analysis. Questions of robust causal inference are practically unavoidable in health, medicine, or social studies. Much of the available data in the clinical and social sciences is observational, and we can only observe one outcome per individual. For example, if one individual took pain reliever for a headache and they now feel better, we don’t know what would have happened to that same individual over the same time period, if they had not taken pain reliever. Taking the pain reliever puts them in the treatment group, but since we don’t know what the control outcome of not taking pain reliever would be (without time travel), how can we say pain reliever caused the headache to go away? . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Introduction",
    "relUrl": "/documentation/user-guide/Introduction"
  },"53": {
    "doc": "Introduction to Causal Inference",
    "title": "Introduction to Matching",
    "content": "When estimating causal effects in an observational setting, one common approach is to match each treatment unit to an identical control unit. Going back to the example, can we find two people sharing every physical attribute, who also had the exact same symptoms, prior to the time when only one of them taking the pain reliever? Secondly, how did their outcomes differ? . In large datasets where we observe many characteristics about individuals, few “identical twins”, (referred to as “exact matches”) exist. What is the best way to match individuals that were treated and controlled? Only once they’re matched are we able to apply common treatment effect estimators to the groups of matched individuals, in order to try to determine the effect of treatment. Further Readings . For more information on causal inference research and its assumptions and issues, we recommend Imbens, Guido W., and Donald B. Rubin. Causal inference in statistics, social, and biomedical sciences. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Introduction#introduction-to-matching",
    "relUrl": "/documentation/user-guide/Introduction#introduction-to-matching"
  },"54": {
    "doc": "Missing Data Handling",
    "title": "Missing Data Handling",
    "content": ". | Introduction to Missing Data Problems in Matching | Determining Which Missing Data Method Is Right For You . | Missing values in the input data | Missing values in the holdout data | . | Further Details on MICE imputation | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Missing-Data",
    "relUrl": "/documentation/user-guide/Missing-Data"
  },"55": {
    "doc": "Missing Data Handling",
    "title": "Introduction to Missing Data Problems in Matching",
    "content": "Missing data is a complicated issue in matching problems. Imputing missing values on datasets is possible, but matches become less interpretable when matching on imputed values, in that it is more difficult to discern why a match was recommended by the matching algorithm. The DAME and FLAME algorithms rely on covariate matching, so the DAME-FLAME package is able to take advantage of this and allows users to match on raw values on data sets with missing data without imputing any data. The DAME-FLAME package also provides options for imputing data. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Missing-Data#introduction-to-missing-data-problems-in-matching",
    "relUrl": "/documentation/user-guide/Missing-Data#introduction-to-missing-data-problems-in-matching"
  },"56": {
    "doc": "Missing Data Handling",
    "title": "Determining Which Missing Data Method Is Right For You",
    "content": "Missing values in the input data . We recommend users set the parameter missing_data_replace=2, where units that have missing values are still matched on, but the covariates they are missing are not used in computing their match. In this option, the underlying algorithm works by replacing each missing value with a unique value, so that in the matching procedure, those covariates simply don’t have a match because their values are not equl to any other values. It is not recommended to use MICE to impute on the matching dataset, as this would be very slow. Users also have the option of imputing their data through any data imputation method of their choice, and then using their imputed dataset as the input data. | Method | Recommendation | Technical Details | missing_data_replace parameter value | . | Do not match units with missing values | Only use if missing values indicate bad unit | Units in the input dataset that have missing data are dropped from the dataset prior to running the algorithms finding the matches | 1 | . | Match units with missing values, but ignore missing values | Recommended for most cases | When pre-processing the input, we place a unique value in place of each missing data point. This will not match any other value, so a unit will only be matched where it’s non-missing covariates match the non-missing covariates of another unit | 2 | . | Impute missing values with MICE | Not recommended | Creates several imputed datasets and iterates over each to find a match according to each dataset. See below for details. | 3 | . Missing values in the holdout data . The “holdout dataset”, if provided, must have the exact same covariates as the input dataset. It is used when training and fitting a machine learning algorithm to determine the best covariates for predicting the outcome. Matches will always be done on the corresponding covariates, but only on the input dataset. We recommend users set the parameter missing_data_replace=1, where units with missing values are dropped, and these units are not used in determining the best covariate set for predicting the outcome. This is the fastest option for the algorithm’s runtime. The error of the predictions will vary depending on how large and informative the observed, non-missing dataset is. Users also have the option of imputing their data through any data imputation method of their choice, and then using their imputed dataset as the input data. | Method | Recommendation | Technical Details | missing_holdout_replace parameter value | . | Do not match units with missing values | Recommended | Units in the holdout dataset that have missing data are dropped from the dataset prior to running the algorithms finding the matches | 1 | . | Impute missing values with MICE | Recommended if interpretability and speed are lower order priorities | Creates several imputed holdout datasets. When choosing the best covariate set for predicting the outcome, iterates over each imputed dataset, and averages the predictive error over all datasets | 2 | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Missing-Data#determining-which-missing-data-method-is-right-for-you",
    "relUrl": "/documentation/user-guide/Missing-Data#determining-which-missing-data-method-is-right-for-you"
  },"57": {
    "doc": "Missing Data Handling",
    "title": "Further Details on MICE imputation",
    "content": "The built-in imputation method that we include is the “Multiple Imputation by Chained Equations” algorithm. This constructs several imputed datasets. It fills in missing values multiple times, creating multiple “complete” datasets. The error of the imputations, and the consistency of the imputations across imputed datasets, is dependent on how predictive the observed data is of the missing values. The underlying MICE implementation is done using scikit learn’s experimental IterativeImpute package, and relies on DecisionTreeRegressions in the imputation process, to ensure that the data generated is fit for unordered categorical data. Further Readings . For more information on the MICE missing data handling technique, we recommend Azur, Melissa J., et al. Multiple imputation by chained equations: what is it and how does it work?. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Missing-Data#further-details-on-mice-imputation",
    "relUrl": "/documentation/user-guide/Missing-Data#further-details-on-mice-imputation"
  },"58": {
    "doc": "Whether to use Matching",
    "title": "To Match or Not To Match",
    "content": "That is the question . | Determining Whether to Use Matching Methods . | The Stable Unit Treatment Value Assumption (SUTVA) | The Unconfoundedness Assumption | Overlap of Treatment and Control Groups | . | Additional Requirements For DAME-FLAME | Challenges in Matching Methods | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/to-match-or-not#to-match-or-not-to-match",
    "relUrl": "/documentation/user-guide/to-match-or-not#to-match-or-not-to-match"
  },"59": {
    "doc": "Whether to use Matching",
    "title": "Determining Whether to Use Matching Methods",
    "content": "Matching of treatment and control units can be a good method in order to determine treatment effects. However, certain criteria must be upheld in order for matching to be an appropriate solution for a given dataset. If these criteria are not upheld, perhaps other approaches to causal inference should be used in place of, or in addition to matching. The Stable Unit Treatment Value Assumption (SUTVA) . Treatments applied to one unit should not affect the outcome of another unit. Units can not interfere with one another. This is reasonable in many situations: If two individuals are not in contact with each other, how would one individual taking a pain medication impact the outcome of another individual. We should also assume that the treatment doesn’t have varying forms, and is completely binary. Individuals can not have taken pain medication of different strengths. The Unconfoundedness Assumption . This is also referred to as “ignorability”. It is important that the outcome is independent of the treatment when observable covaraiates are held constant. Omitted variable bias is a common issue that occurs when a variable impacts both treatment and outcomes, and appears in a bias of treatment effect estimates. In the example about pain medications, if a researcher fails to include in their dataset some underlying health condition that impacts response to pain medication, the impact of taking pain medication for a headache might be evaluated incorrectly. Overlap of Treatment and Control Groups . A common problem in causal inference is overlap or imbalance between treatment and control groups. A treatment and control group would have no overlap if none of the covariates have the same values. In this case, the FLAME and DAME algorithms would not find any matches, and no treatment effect estimates would be possible. A more moderate issue is partial overlap. In this case, some units do not have matches. Because the DAME-FLAME package allows for algorithm controls, even if all units could be matched in theory, users of the algorithm might prefer to avoid matching all units. Regardless of the cause, units that are unmatched do not have a CATE estimate, and they are not included in the treatment effect calculations either. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/to-match-or-not#determining-whether-to-use-matching-methods",
    "relUrl": "/documentation/user-guide/to-match-or-not#determining-whether-to-use-matching-methods"
  },"60": {
    "doc": "Whether to use Matching",
    "title": "Additional Requirements For DAME-FLAME",
    "content": "Since DAME-FLAME is a package for matching treatment and control groups, we require all of the above criteria for users. Additionally, we impose one additional crucial requirement: that the datasets that contain discrete observational data. The outcome variable can be continuous, but we impose this requirement on all of the covariates. We do not recommend users bin continous covariates unless they are confident they are in a way that is a typical, research driven separation. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/to-match-or-not#additional-requirements-for-dame-flame",
    "relUrl": "/documentation/user-guide/to-match-or-not#additional-requirements-for-dame-flame"
  },"61": {
    "doc": "Whether to use Matching",
    "title": "Challenges in Matching Methods",
    "content": "“Exact matching” isn’t possible when we a dataset has lots of characteristics about individuals, or is high dimensional. So, matching methods performing the best-possible alternative should be interpretable. Users of matching algorithms need to be able to easily understand which covariates were selected to be most important to their outcome, and need be able to find out why they were selected. This is important so that causal analysis can provide crucial information on who benefits from treatment most, where resources should be spent for future treatments, and why some individuals benefit from treatment while others were not. This can also help researchers determine what type of additional data must be collected. Secondly, the matches should also be high quality. If an oracle could tell us the exact result of doing treatment on any individual whose treatment we did not observe, then would we find that our estimate of the effect of treatment on that individual is accurate? . Further Readings . For more information on causal inference research and its assumptions and issues, we recommend Imbens, Guido W., and Donald B. Rubin. Causal inference in statistics, social, and biomedical sciences. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/to-match-or-not#challenges-in-matching-methods",
    "relUrl": "/documentation/user-guide/to-match-or-not#challenges-in-matching-methods"
  },"62": {
    "doc": "Whether to use Matching",
    "title": "Whether to use Matching",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/to-match-or-not",
    "relUrl": "/documentation/user-guide/to-match-or-not"
  },"63": {
    "doc": "Treatment Effect Estimates",
    "title": "Treatment Effect Estimates",
    "content": "We define and discuss the most common metrics that researchers estimate when evaluating the results of a treatment. | Notes on Statistical Assumptions . | Unconfoundedness | Overlap of Treatment and Control Groups | . | Standard Notation for Statistical Definitions | Conditional Average Treatment Effect (CATE) | Average Treatment Effect (ATE) | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Treatment-Effects",
    "relUrl": "/documentation/user-guide/Treatment-Effects"
  },"64": {
    "doc": "Treatment Effect Estimates",
    "title": "Notes on Statistical Assumptions",
    "content": "Unconfoundedness . As an important note, these metrics will be biased if the unconfoundedness or ignorability assumption does not hold. In other words, it is best to use these metrics if the outcome is independent of the treatment when observable covaraiates are held constant. The bias will be as small as possible if many covariates are included, or users include any covariate that would have an impact on the outcome. In a case where a user is conflicted on whether or not to include a particular covariates, we recommend users consider including all variables and performing a match, while observing how quickly in the algorithm that covariate is dropped with the verbose=3 parameter. If the covariate is dropped in an early iteration with a low predictive error, it can be assumed that covariate is only weakly correlated with the outcome. Users can then perform a match a second time after removing weakly correlated covariates from their dataset if they wish. We recommend this approach, in order to ensure that any important covariates are matched on and bias of these estimators is minimized. Overlap of Treatment and Control Groups . A common problem in causal inference is overlap or imbalance between treatment and control groups. A treatment and control group would have no overlap if none of the covariates have the same values. In this case, the FLAME and DAME algorithms would not find any matches, and no treatment effect estimates would be possible. A more moderate issue is partial overlap. In this case, some units do not have matches. Because the DAME-FLAME package allows for algorithm controls, even if all units could be matched in theory, users of the algorithm might prefer to avoid matching all units. Regardless of the cause, units that are unmatched do not have a CATE estimate, and they are not included in the ATE calculations either. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Treatment-Effects#notes-on-statistical-assumptions",
    "relUrl": "/documentation/user-guide/Treatment-Effects#notes-on-statistical-assumptions"
  },"65": {
    "doc": "Treatment Effect Estimates",
    "title": "Standard Notation for Statistical Definitions",
    "content": "We refer to each matched unit as unit $i$. There are there are $N$ matched unit in total. We may interchangeably refer to the matched units as ‘individuals’ or ‘observations’, and although we will not always preface by saying they are ‘matched units’, please remember that they must be in order to be included in treatment effects. There are $r$ covariates upon which we have observed characteristics about each of the individuals prior to treatment, and these are $x_1$ through $x_r$. For a given unit $i$, its vector of covariates is $X_i$ . Let the treatment indicator for any unit $i$ be indicated as $T_i$. We let $Y_i$ be the outcome for individual $i$. We use this interchangably with the notation $Y_i(T_i)$, so we write $Y_i(0)$ to indicate the outcome of $i$ if $i$ is in the control group, and $Y_i(1)$ if $i$ is in the treated group. Lastly, we introduce notation for the matched grous. We label a matched group as $m$. The size of a matched group is $| m\\vert$, and this is the number of units in the group. There are $M$ matched groups in total. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Treatment-Effects#standard-notation-for-statistical-definitions",
    "relUrl": "/documentation/user-guide/Treatment-Effects#standard-notation-for-statistical-definitions"
  },"66": {
    "doc": "Treatment Effect Estimates",
    "title": "Conditional Average Treatment Effect (CATE)",
    "content": "This is defined as the average treatment effect conditional on particular covariates. We provide an implementation of CATE that allows a user to input a unit $i$, and then will output the CATE based on the covariates that $i$ was matched on. Formally, CATE for covariates $X_i$ is $\\frac{1}{N}\\sum_{i=1}^N\\mathbb{E}[Y(1)-Y(0)|X_i]$ . Since our units are each matched in a group with other units that share treatment indicator as well as the opposite indicator, each unit in a matched group will have the same CATE. For a unit $i$ in matched group $M$ of size $||M||$, we estimate the CATE of $i$ as: \\(\\frac{1}{\\|M\\|}\\sum_{i:T_i=1}[\\hat{Y}_i(1)]-\\frac{1}{\\|M\\|}\\sum_{i:T_i=0}[\\hat{Y}_i(0)]\\) . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Treatment-Effects#conditional-average-treatment-effect-cate",
    "relUrl": "/documentation/user-guide/Treatment-Effects#conditional-average-treatment-effect-cate"
  },"67": {
    "doc": "Treatment Effect Estimates",
    "title": "Average Treatment Effect (ATE)",
    "content": "The Average Treatment Effect for a population is generally $\\mathbb{E}[Y(1)-Y(0)]$. We estimate this in a way that is robust to units reappearing in matched groups, according to the parameter repeats=True. Our estimate will ensure that units appearing in multiple matched groups are weighted accordingly, as well as that their influence in their groups is accounted for. Let $q_i$ denote the number of matched groups that unit $i$ appears in. Then, for a given matched group $m$, the number of matches made by the units in $m$ is $w_m=\\sum_{i=1}^{|m|}\\frac{1}{q_i}$. Since the CATE of each unit in a group is the same, we can call the CATE of group $m$ $\\mathit{CATE}_m$. So, finally, we estimate ATE as $\\frac{\\sum_{m\\in\\mathbb{M}}CATE_m*w_m}{\\sum_{m\\in\\mathbb{M}}w_m}$ . Further Readings . For more information on treatment effects, we recommend Imbens, Guido W. Nonparametric estimation of average treatment effects under exogeneity: A review. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/Treatment-Effects#average-treatment-effect-ate",
    "relUrl": "/documentation/user-guide/Treatment-Effects#average-treatment-effect-ate"
  },"68": {
    "doc": "User Guide",
    "title": "User Guide",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/documentation/user-guide/",
    "relUrl": "/documentation/user-guide/"
  },"69": {
    "doc": "Getting Started",
    "title": "Getting Started",
    "content": "Here, we aim to get you launched . | Dependencies | Installation | Quickstart Example | . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/getting-started",
    "relUrl": "/getting-started"
  },"70": {
    "doc": "Getting Started",
    "title": "Dependencies",
    "content": "This package requires prior installation of . | Python (&gt;= 3.0) | NumPy (&gt;= 1.17.5) | Scikit-Learn (&gt;= 0.22.1)) | Pandas (todo: check) | . If your computer system does not have python 3.*, install from here. If your python version does not have the Pandas, Scikit learn, or Numpy packages, install from here . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/getting-started#dependencies",
    "relUrl": "/getting-started#dependencies"
  },"71": {
    "doc": "Getting Started",
    "title": "Installation",
    "content": "The DAME-FLAME Python Package is available for download on the almost-matching-exactly Github or via PyPi (recommended): . pip install dame-flame . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/getting-started#installation",
    "relUrl": "/getting-started#installation"
  },"72": {
    "doc": "Getting Started",
    "title": "Quickstart Example",
    "content": "We run the DAME function with the following basic command. In this example, we provide only the basic inputs: (1) input data as a dataframe or file, (2) the name of the outcome column, and (3) the name of the treatment column. In this example, because of the toy sized small dataset, we set the holdout dataset equal to the complete input dataset. import pandas as pd import dame_flame df = pd.read_csv(\"dame_flame/data/sample.csv\") model = dame_flame.matching.DAME(repeats=False, verbose=1, early_stop_iterations=False) model.fit(holdout_data=df) result = model.predict(input_data=df) print(result) #&gt; x1 x2 x3 x4 #&gt; 0 0 1 1 * #&gt; 1 0 1 1 * #&gt; 2 1 0 * 1 #&gt; 3 1 0 * 1 print(model.groups_per_unit) #&gt; 0 1.0 #&gt; 1 1.0 #&gt; 2 1.0 #&gt; 3 1.0 print(model.units_per_group) #&gt; [[2, 3], [0, 1]] . result is type Data Frame. The dataframe contains all of the units that were matched, and the covariates and corresponding values, that it was matched on. The covariates that each unit was not matched on is denoted with a “ * “ character. model.groups_per_unit is a Data Frame with a column of unit weights which specifies the number of groups that each unit was placed in. model.units_per_group is a list in which each list is a main matched group, and the unit ids that belong to that group. Additional values based on additional optional parameters can be retrieved, detailed in additional documentation below. To find the main matched group of a particular unit or group of units after DAME has been run, use the function MG: . mmg = dame_flame.utils.post_processing.MG(matching_object=model, unit_id=0) print(mmg) #&gt; x1 x2 x3 x4 treated outcome #&gt; 0 0 1 1 * 0 5 #&gt; 1 0 1 1 * 1 6 . To find the conditional treatment effect (CATE) for the main matched group of a particular unit or group of units, use the function CATE: . te = dame_flame.utils.post_processing.CATE(matching_object=model, unit_id=0) print(te) #&gt; 3.0 . To find the average treatment effect (ATE) or average treatment effect on the treated (ATT), use the functions ATE and ATT, respectively: . ate = dame_flame.utils.post_processing.ATE(matching_object=model) print(ate) #&gt; 2.0 att = dame_flame.utils.post_processing.MG(matching_object=model) print(att) #&gt; 2.0 . ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/getting-started#quickstart-example",
    "relUrl": "/getting-started#quickstart-example"
  },"73": {
    "doc": "Home",
    "title": "Welcome to the DAME-FLAME Python Package Documentation!",
    "content": "View us on GitHub . dame-flame is a Python package for performing matching for observational causal inference on datasets containing discrete covariates. It implements the Dynamic Almost Matching Exactly (DAME) and Fast, Large-Scale Almost Matching Exactly (FLAME) algorithms, which match treatment and control units on subsets of the covariates. The resulting matched groups are interpretable, because the matches are made on covariates (rather than, for instance, propensity scores), and high-quality, because machine learning is used to determine which covariates are important to match on. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/#welcome-to-the-dame-flame-python-package-documentation",
    "relUrl": "/#welcome-to-the-dame-flame-python-package-documentation"
  },"74": {
    "doc": "Home",
    "title": "Contact",
    "content": "Please reach out to let our team know if you’re using this, or if you have any questions! Contact Neha Gupta at neha.r.gupta@duke.edu. ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/#contact",
    "relUrl": "/#contact"
  },"75": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "http://localhost:4000/DAME-FLAME-Python-Package/",
    "relUrl": "/"
  }
}
