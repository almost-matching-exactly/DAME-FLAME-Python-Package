{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Testing file\"\"\"\n",
    "# author: Neha Gupta, Duke University\n",
    "# Copyright Duke University 2020\n",
    "# License: MIT\n",
    "\n",
    "from dame_flame import matching\n",
    "from dame_flame.utils.data import *\n",
    "from dame_flame.utils.post_processing import *\n",
    "import unittest\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def check_statistics(model,unit_id = 1):\n",
    "    ATE_ = ATE(model)\n",
    "    ATT_ = ATT(model)\n",
    "    MG_ = MG(model,unit_id)\n",
    "    CATE_ = CATE(model,unit_id)\n",
    "    \n",
    "    if len(model.units_per_group) == 0:\n",
    "        return True\n",
    "    if len(model.groups_per_unit) == 0:\n",
    "        return True\n",
    "    if type(ATE_) == np.nan:\n",
    "        print(\"ATE: \" + str(ATE_))\n",
    "        return True\n",
    "    if type(ATT_) == np.nan:\n",
    "        print(\"ATT:\" + str(ATT_))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "class TestFlame(unittest.TestCase):\n",
    "    '''\n",
    "    This file tests the overall FLAME algorithm against results that were\n",
    "    confirmed to be correct by comparing to the FLAME R package.\n",
    "    '''\n",
    "    \n",
    "    def test_large_C_repeats_F(self):\n",
    "        \n",
    "        df_path = os.path.join((os.path.dirname(__file__)), 'basicTestData.csv')\n",
    "        df = pd.read_csv(df_path)\n",
    "    \n",
    "        holdout_path = os.path.join((os.path.dirname(__file__)), 'basicHoldoutData.csv')\n",
    "        holdout = pd.read_csv(holdout_path)\n",
    "        model = matching.FLAME(repeats=False, verbose=1)\n",
    "        model.fit(holdout_data=holdout)\n",
    "        algo_output = model.predict(df, C=100000)\n",
    "        \n",
    "        result_path = os.path.join((os.path.dirname(__file__)), 'basicResultData.csv')\n",
    "        result = pd.read_csv(result_path, index_col=\"Unnamed: 0\")\n",
    "        \n",
    "        dfs_equal = 1\n",
    "        try:\n",
    "            for index in result.index:\n",
    "                for col in result.columns:\n",
    "                    if (result.loc[index, col] != \"*\" and\n",
    "                        algo_output.loc[index, col] != \"*\" and\n",
    "                        int(result.loc[index, col]) != int(algo_output.loc[index, col])):\n",
    "                            print(\"index, col\", index, col)\n",
    "                            dfs_equal = 0\n",
    "                            break\n",
    "        except (KeyError, ValueError):\n",
    "            # We would hit this block if theres a key error, so df columns\n",
    "            # are not equal or have different units, or weird entry in df, (string)\n",
    "            dfs_equal = 0\n",
    "        \n",
    "        self.assertEqual(1, dfs_equal,\n",
    "                         msg='Data frames not equal on index {0}, col {1}'.format(index, col))\n",
    "        \n",
    "    def test_PE_F(self):\n",
    "        for adaptive_weights in [False, 'ridge', 'decisiontree', 'ridgeCV','decisiontreeCV']: #\n",
    "            is_correct = 1\n",
    "            try:\n",
    "                model = None\n",
    "                if adaptive_weights == False:\n",
    "                    df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                              num_cov=7, min_val=0,\n",
    "                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                    holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                                          num_cov=7, min_val=0,\n",
    "                                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                    covar_importance = np.array([4,3,2,1,0,0,0])\n",
    "                    weight_array = covar_importance/covar_importance.sum()\n",
    "                    model = matching.FLAME(repeats=False, verbose=0,adaptive_weights =adaptive_weights)\n",
    "                    model.fit(holdout_data=holdout,weight_array = list(weight_array))\n",
    "                    output = model.predict(df)\n",
    "                else:\n",
    "                    df, true_TE = generate_uniform_given_importance()\n",
    "                    holdout, true_TE = generate_uniform_given_importance()\n",
    "                    model = matching.FLAME(repeats=False, verbose=0,adaptive_weights =adaptive_weights)\n",
    "                    model.fit(holdout_data=holdout)\n",
    "                    output = model.predict(df)\n",
    "\n",
    "                if check_statistics(model):\n",
    "                    is_correct = 0\n",
    "                    \n",
    "\n",
    "            except (KeyError, ValueError):\n",
    "                is_correct = 0\n",
    "\n",
    "            self.assertEqual(1, is_correct,\n",
    "                             msg='FLAME-Error when we use PE method: {0} '.format(str(adaptive_weights)))\n",
    "\n",
    "    def test_datasets_F(self):\n",
    "        df_path = os.path.join((os.path.dirname(__file__)), 'basicTestData.csv')\n",
    "\n",
    "        for gen in [generate_uniform_given_importance,generate_binomial_given_importance,generate_binomial_decay_importance,df_path]:\n",
    "            is_correct = 1\n",
    "            try:\n",
    "                df = None\n",
    "                holdout = None\n",
    "                if type(gen) != str:\n",
    "                    df, true_TE = gen()\n",
    "                    holdout, true_TE = gen()\n",
    "                else:\n",
    "                    df  = gen\n",
    "                    holdout = gen\n",
    "                model = matching.FLAME(repeats=False)\n",
    "                model.fit(holdout_data=holdout)\n",
    "                output = model.predict(df)\n",
    "            \n",
    "                if check_statistics(model):\n",
    "                    is_correct = 0\n",
    "                    break\n",
    "\n",
    "            except (KeyError, ValueError):\n",
    "                is_correct = 0\n",
    "\n",
    "            self.assertEqual(1, is_correct,\n",
    "                             msg='FLAME-Error when we use the dataset generated by {0} '.format(str(gen)))\n",
    "    \n",
    "    def test_repeats_F(self):\n",
    "        #Test other parameters\n",
    "        df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                              num_cov=7, min_val=0,\n",
    "                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "        holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                              num_cov=7, min_val=0,\n",
    "                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            model = matching.FLAME(repeats=True)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            \n",
    "        except (KeyError, ValueError):\n",
    "            is_correct = 0\n",
    "\n",
    "        self.assertEqual(1, is_correct, msg='FLAME-Error when repeat = True')\n",
    "        \n",
    "    def test_verbose_F(self):\n",
    "        #Test verbose\n",
    "        df, true_TE = generate_uniform_given_importance()\n",
    "        for verbose in [0,1,2,3]:\n",
    "            is_correct = 1\n",
    "            try:\n",
    "                df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000,\n",
    "                                                              num_cov=7, min_val=0,\n",
    "                                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                                      num_cov=7, min_val=0,\n",
    "                                                          max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                covar_importance = np.array([4,3,2,1,0,0,0])\n",
    "                weight_array = covar_importance/covar_importance.sum()\n",
    "                model = matching.FLAME(missing_data_replace = 2, want_bf = True, verbose = verbose)\n",
    "                model.fit(holdout_data=holdout)\n",
    "                output = model.predict(df)\n",
    "                model = matching.FLAME(repeats=True,verbose=verbose)\n",
    "                model.fit(holdout_data=0.5)\n",
    "                output = model.predict(df)\n",
    "                if check_statistics(model):\n",
    "                    is_correct = 0\n",
    "                    break\n",
    "            except (KeyError, ValueError):\n",
    "                is_correct = 0\n",
    "\n",
    "            self.assertEqual(1, is_correct, msg='FLAME-Error when verbose ={0}'.format(verbose))\n",
    "            \n",
    "        \n",
    "    def test_data_split_F(self):\n",
    "        #Test data split\n",
    "        df, true_TE = generate_uniform_given_importance(num_control=3000, num_treated=3000)\n",
    "\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            for holdout in [0.3,0.5,0.7]:\n",
    "                model = matching.FLAME(repeats=True)\n",
    "                model.fit(holdout_data=holdout)\n",
    "                output = model.predict(df)\n",
    "                if check_statistics(model):\n",
    "                    is_correct = 0\n",
    "                    break\n",
    "        except (KeyError, ValueError):\n",
    "            is_correct = 0\n",
    "\n",
    "        self.assertEqual(1, is_correct, msg='FLAME-Error when holdout = {0}'.format(holdout))\n",
    "\n",
    "        \n",
    "    def test_miss_data_F(self):\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            for missing_holdout_replace in [0,1,2]:\n",
    "                for missing_data_replace in [0,1,2,3]:\n",
    "                    df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000)\n",
    "                    #Create missing df\n",
    "                    m,n = df.shape\n",
    "                    for i in range(int(m/100)):\n",
    "                        for j in [0,int(n/2)]:\n",
    "                            df.iloc[i,j] = np.nan\n",
    "                    holdout = df.copy()\n",
    "\n",
    "                    model = matching.FLAME(missing_holdout_replace = missing_holdout_replace,missing_data_replace=missing_data_replace )\n",
    "                    model.fit(holdout_data=holdout)\n",
    "                    output = model.predict(df)\n",
    "                    if check_statistics(model):\n",
    "                        is_correct = 0\n",
    "                        break\n",
    "\n",
    "        except (KeyError, ValueError):\n",
    "            is_correct = 0\n",
    "        self.assertEqual(1, is_correct, msg='FLAME-Error when do missing data'\\\n",
    "                             'handling with missing_holdout_replace = {0},missing_data_replace{1}'.format(missing_holdout_replace,missing_data_replace))\n",
    "        \n",
    "    def test_want_pebf_F(self):\n",
    "        #Test\n",
    "        df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                              num_cov=7, min_val=0,\n",
    "                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "        holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                              num_cov=7, min_val=0,\n",
    "                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            for want_pe in [False, True]:\n",
    "                for want_bf in [False, True]:\n",
    "                    model = matching.FLAME(want_pe=want_pe,want_bf=want_bf)\n",
    "                    model.fit(holdout_data=holdout)\n",
    "                    output = model.predict(df)\n",
    "                    if check_statistics(model) or (want_pe and len(model.pe_each_iter)==0) or (want_bf and len(model.bf_each_iter)==0):\n",
    "                        is_correct = 0\n",
    "                        break\n",
    "\n",
    "        except (KeyError, ValueError):\n",
    "            is_wrong = 0\n",
    "        self.assertEqual(1, is_correct, msg='FLAME Error when want_pe = {0} want_bf = {1}'.format(str(want_pe),str(want_bf)))\n",
    "        \n",
    "    def test_pre_dame_F(self):\n",
    "        df, true_TE = generate_uniform_given_importance(num_control=500, num_treated=500,\n",
    "                                  num_cov=7, min_val=0,\n",
    "                                  max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "        holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                              num_cov=7, min_val=0,\n",
    "                                                  max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            covar_importance = np.array([4,3,2,1,0,0,0])\n",
    "            weight_array = covar_importance/covar_importance.sum()\n",
    "            for x in [False, True]:\n",
    "                for y in [False, True]:\n",
    "                    model1 = matching.FLAME(repeats=x,want_pe = y, want_bf = y,verbose=0,adaptive_weights = False)\n",
    "                    model1.fit(holdout_data=holdout,weight_array = list(weight_array))\n",
    "                    output = model1.predict(df, pre_dame = True)\n",
    "                    model2 = matching.FLAME(repeats=x, want_pe = y, want_bf = y,verbose=0,adaptive_weights = 'decisiontreeCV')\n",
    "                    model2.fit(holdout_data=holdout)\n",
    "                    output = model2.predict(df, pre_dame = True)\n",
    "\n",
    "                    output = model2.predict(df, pre_dame = True)\n",
    "                    if check_statistics(model1) or check_statistics(model2) :\n",
    "                        is_correct = 0\n",
    "                \n",
    "        except (KeyError, ValueError):\n",
    "            is_correct = 0\n",
    "\n",
    "        self.assertEqual(1, is_correct,\n",
    "                         msg='FLAME-Error when we use pre_dame')\n",
    "        \n",
    "    def test_other_param_F(self):\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000,\n",
    "                                                  num_cov=7, min_val=0,\n",
    "                                                  max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "            holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                                  num_cov=7, min_val=0,\n",
    "                                                      max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "            \n",
    "            model = matching.FLAME( early_stop_pe= 1, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            model = matching.FLAME( stop_unmatched_c= True, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            model = matching.FLAME(stop_unmatched_t= True, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            model = matching.FLAME(early_stop_un_c_frac = 0.5, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            model = matching.FLAME(early_stop_un_t_frac = 0.5, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            model = matching.FLAME(early_stop_iterations= 2, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "                \n",
    "        except (KeyError, ValueError):\n",
    "            is_correct = 0\n",
    "        self.assertEqual(1, is_correct, msg='FLAME-Error when other parameters')\n",
    "\n",
    "\n",
    "class TestDame(unittest.TestCase):\n",
    "\n",
    "\n",
    "            \n",
    "    def test_PE_F(self):\n",
    "        for adaptive_weights in [ 'ridge', 'decisiontree', 'ridgeCV','decisiontreeCV']: #False,\n",
    "            is_correct = 1\n",
    "            try:\n",
    "                model = None\n",
    "                if adaptive_weights == False:\n",
    "                    df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                              num_cov=7, min_val=0,\n",
    "                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                    holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                                          num_cov=7, min_val=0,\n",
    "                                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                    covar_importance = np.array([4,3,2,1,0,0,0])\n",
    "                    weight_array = covar_importance/covar_importance.sum()\n",
    "                    model = matching.DAME(repeats=False, verbose=0,adaptive_weights =adaptive_weights)\n",
    "                    model.fit(holdout_data=holdout,weight_array = list(weight_array))\n",
    "                    output = model.predict(df)\n",
    "                else:\n",
    "                    df, true_TE = generate_uniform_given_importance()\n",
    "                    holdout, true_TE = generate_uniform_given_importance()\n",
    "                    model = matching.DAME(repeats=False, verbose=0,adaptive_weights =adaptive_weights)\n",
    "                    model.fit(holdout_data=holdout)\n",
    "                    output = model.predict(df)\n",
    "\n",
    "                if check_statistics(model):\n",
    "                    is_correct = 0\n",
    "                    break\n",
    "\n",
    "            except (KeyError, ValueError):\n",
    "                is_correct = 0\n",
    "\n",
    "\n",
    "            self.assertEqual(1, is_correct,\n",
    "                             msg='DAME-Error when we use PE method: {0} '.format(adaptive_weights))\n",
    "\n",
    "    def test_datasets_F(self):\n",
    "        df_path = os.path.join((os.path.dirname(__file__)), 'basicTestData.csv')\n",
    "        for gen in [generate_uniform_given_importance,generate_binomial_given_importance,generate_binomial_decay_importance,df_path]:\n",
    "            is_correct = 1\n",
    "            try:\n",
    "                df = None\n",
    "                holdout = None\n",
    "                if type(gen) != str:\n",
    "                    df, true_TE = gen()\n",
    "                    holdout, true_TE = gen()\n",
    "                else:\n",
    "                    df  = gen\n",
    "                    holdout = gen\n",
    "                model = matching.DAME(repeats=False)\n",
    "                model.fit(holdout_data=holdout)\n",
    "                output = model.predict(df)\n",
    "                \n",
    "                        \n",
    "                if check_statistics(model):\n",
    "                    is_correct = 0\n",
    "                    break\n",
    "\n",
    "            except (KeyError, ValueError):\n",
    "                is_correct = 0\n",
    "\n",
    "            self.assertEqual(1, is_correct,\n",
    "                             msg='DAME-Error when we use the dataset generated by {0} '.format(str(gen)))\n",
    "    \n",
    "    def test_repeats_F(self):\n",
    "        #Test other parameters\n",
    "        df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                               num_cov=7, min_val=0,\n",
    "                                               max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "        holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                               num_cov=7, min_val=0,\n",
    "                                               max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            model = matching.DAME(repeats=True)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "\n",
    "        except (KeyError, ValueError):\n",
    "            is_correct = 0\n",
    "        self.assertEqual(1, is_correct, msg='DAME-Error when repeat = True')\n",
    "\n",
    "    def test_verbose_F(self):\n",
    "        #Test verbose\n",
    "        df, true_TE = generate_uniform_given_importance()\n",
    "        for verbose in [0,1,2,3]:\n",
    "            is_correct = 1\n",
    "            try:\n",
    "                df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000,\n",
    "                                                              num_cov=7, min_val=0,\n",
    "                                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                                      num_cov=7, min_val=0,\n",
    "                                                          max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                covar_importance = np.array([4,3,2,1,0,0,0])\n",
    "                weight_array = covar_importance/covar_importance.sum()\n",
    "                model = matching.DAME(missing_data_replace = 2, want_bf = True, verbose = verbose)\n",
    "                model.fit(holdout_data=holdout)\n",
    "                output = model.predict(df)\n",
    "\n",
    "                model = matching.DAME(verbose=verbose) # repeats = True\n",
    "                model.fit(holdout_data=0.5)\n",
    "                output = model.predict(df)\n",
    "                if check_statistics(model):\n",
    "                    is_correct = 0\n",
    "                    break\n",
    "            except (KeyError, ValueError):\n",
    "                is_correct = 0\n",
    "\n",
    "            self.assertEqual(1, is_correct, msg='DAME-Error when verbose ={0}'.format(verbose))\n",
    "            \n",
    "        \n",
    "    def test_data_split_F(self):\n",
    "        #Test data split\n",
    "        df, true_TE = generate_uniform_given_importance(num_control=3000, num_treated=3000)\n",
    "\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            for holdout in [0.3,0.5,0.7]:\n",
    "                model = matching.DAME(repeats=True)\n",
    "                model.fit(holdout_data=holdout)\n",
    "                output = model.predict(df)\n",
    "                if check_statistics(model):\n",
    "                    is_correct = 0\n",
    "                    break\n",
    "        except (KeyError, ValueError):\n",
    "            is_correct = 0\n",
    "\n",
    "        self.assertEqual(1, is_correct, msg='DAME-Error when holdout = {0}'.format(holdout))\n",
    "\n",
    "        \n",
    "    def test_miss_data_F(self):\n",
    "\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            for missing_holdout_replace in [0,1,2]:\n",
    "                for missing_data_replace in [0,1,2,3]:\n",
    "                    #Test missig data handling\n",
    "                    df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000)\n",
    "                    #Create missing df\n",
    "                    m,n = df.shape\n",
    "                    for i in range(int(m/10)):\n",
    "                        for j in [0,int(n/2)]:\n",
    "                            df.iloc[i,j] = np.nan\n",
    "                    holdout = df.copy()\n",
    "                    model = matching.DAME(repeats = False,missing_holdout_replace = missing_holdout_replace,missing_data_replace=missing_data_replace )\n",
    "                    model.fit(holdout_data=holdout)\n",
    "                    output = model.predict(df)\n",
    "                    if check_statistics(model):\n",
    "                        is_correct = 0\n",
    "                        break\n",
    "\n",
    "        except (KeyError, ValueError):\n",
    "            is_correct = 0\n",
    "        self.assertEqual(1, is_correct, msg='DAME-Error when do missing data'\\\n",
    "                             'handling with missing_holdout_replace = {0},missing_data_replace{1}'.format(missing_holdout_replace,missing_data_replace))\n",
    "        \n",
    "    def test_want_pebf_F(self):\n",
    "        #Test\n",
    "        df, true_TE = generate_uniform_given_importance(num_control=3000, num_treated=3000,\n",
    "                                              num_cov=6, min_val=0,\n",
    "                                              max_val=3, covar_importance=[4,3,2,1,0,0])\n",
    "        holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                              num_cov=6, min_val=0,\n",
    "                                              max_val=3, covar_importance=[4,3,2,1,0,0])\n",
    "\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            for want_pe in [False, True]:\n",
    "                for want_bf in [False, True]:\n",
    "                    model = matching.DAME(want_pe=want_pe,want_bf=want_bf)\n",
    "                    model.fit(holdout_data=holdout)\n",
    "                    output = model.predict(df)\n",
    "                    if check_statistics(model) or (want_pe and len(model.pe_each_iter)==0) or (want_bf and len(model.bf_each_iter)==0):\n",
    "                        is_correct = 0\n",
    "                        break\n",
    "\n",
    "        except (KeyError, ValueError):\n",
    "            is_correct = 0\n",
    "        self.assertEqual(1, is_correct, msg='DAME Error when want_pe = {0} want_bf = {1}'.format(str(want_pe),str(want_bf)))\n",
    "        \n",
    "    def test_other_param_F(self):\n",
    "        is_correct = 1\n",
    "        try:\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000,\n",
    "                                                  num_cov=7, min_val=0,\n",
    "                                                  max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "            holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                                  num_cov=7, min_val=0,\n",
    "                                                      max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "\n",
    "            model = matching.DAME( early_stop_pe= 1, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            model = matching.DAME( stop_unmatched_c= True, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            model = matching.DAME(stop_unmatched_t= True, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            model = matching.DAME(early_stop_un_c_frac = 0.5, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            model = matching.DAME(early_stop_un_t_frac = 0.5, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "            model = matching.DAME(early_stop_iterations= 2, verbose=0)\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "            if check_statistics(model):\n",
    "                is_correct = 0\n",
    "\n",
    "        except (KeyError, ValueError):\n",
    "            is_correct = 0\n",
    "        self.assertEqual(1, is_correct, msg='DAME-Error when other parameters')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Test_exceptions(unittest.TestCase):\n",
    "    \n",
    "    def test_false_dataset(self):\n",
    "        def broken_false_dataset():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000)\n",
    "            holdout, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000)\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(False)\n",
    "\n",
    "            \n",
    "        with self.assertRaises(Exception) as false_dataset:\n",
    "            broken_false_dataset()\n",
    "            \n",
    "        self.assertTrue(\"Need to specify either csv file name or pandas data \"\\\n",
    "                        \"frame in parameter 'input_data'\" in str(false_dataset.exception))\n",
    "        \n",
    "    def test_false_early_stop_un_t_frac(self):\n",
    "        def broken_early_stop_un_t_frac():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(early_stop_un_t_frac = -1)\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as early_stop_un_t_frac:\n",
    "            broken_early_stop_un_t_frac()\n",
    "            \n",
    "        self.assertTrue('The value provided for the early stopping critera '\\\n",
    "                        'of proportion of unmatched treatment units needs to '\\\n",
    "                        'be between 0.0 and 1.0' in str(early_stop_un_t_frac.exception))\n",
    "    \n",
    "    def test_false_early_stop_un_c_frac(self):\n",
    "        def broken_early_stop_un_c_frac():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(early_stop_un_c_frac = -1)\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as early_stop_un_c_frac:\n",
    "            broken_early_stop_un_c_frac()\n",
    "            \n",
    "        self.assertTrue('The value provided for the early stopping critera '\\\n",
    "                        'of proportion of unmatched control units needs to '\\\n",
    "                        'be between 0.0 and 1.0' in str(early_stop_un_c_frac.exception))\n",
    "        \n",
    "        \n",
    "    def test_false_early_stop_iterations(self):\n",
    "        def broken_early_stop_iterations():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(early_stop_iterations = True)\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as early_stop_iterations:\n",
    "            broken_early_stop_iterations()\n",
    "            \n",
    "        self.assertTrue('The value provided for early_stop_iteration needs '\\\n",
    "                        'to be an integer number of iterations, or False if '\\\n",
    "                        'not stopping early based on the number of iterations' in str(early_stop_iterations.exception))\n",
    "    def test_false_early_stop_pe_frac(self):\n",
    "        def broken_early_stop_pe_frac():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(early_stop_pe_frac = 123)\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as early_stop_pe_frac:\n",
    "            broken_early_stop_pe_frac()\n",
    "            \n",
    "        self.assertTrue('The value provided for the early stopping critera of'\\\n",
    "                        ' PE needs to be between 0.0 and 1.0' in str(early_stop_pe_frac.exception))\n",
    "\n",
    "#     def test_false_verbose(self):\n",
    "#         def broken_verbose():\n",
    "#             df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "#             model = matching.FLAME(verbose = 9)\n",
    "#             model.fit(holdout_data=df)\n",
    "#             output = model.predict(df)\n",
    "\n",
    "#         with self.assertRaises(Exception) as verbose:\n",
    "#             broken_verbose()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. The verbose option must be'\\\n",
    "#                         'the integer 0,1,2 or 3.' in str(verbose.exception))\n",
    "    def test_false_weight_array_type(self):\n",
    "        def broken_weight_array_type():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(adaptive_weights = False)\n",
    "            model.fit(holdout_data=df, weight_array = np.array([1,2,3,4,5]))\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as weight_array_type:\n",
    "            broken_weight_array_type()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. A weight array of type'\\\n",
    "                            'array needs to be provided when the'\\\n",
    "                            'parameter adaptive_weights == True' in str(weight_array_type.exception))\n",
    "\n",
    "    def test_false_weight_array_len(self):\n",
    "        def broken_weight_array_len():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(adaptive_weights = False)\n",
    "            model.fit(holdout_data=df, weight_array = [1])\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as weight_array_len:\n",
    "            broken_weight_array_len()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. Weight array size not equal'\\\n",
    "                            ' to number of columns in dataframe' in str(weight_array_len.exception))\n",
    "        \n",
    "        \n",
    "    def test_false_weight_array_sum(self):\n",
    "        def broken_weight_array_sum():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(adaptive_weights = False)\n",
    "            model.fit(holdout_data=df, weight_array = [1,1,1,1])\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as weight_array_sum:\n",
    "            broken_weight_array_sum()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. Weight array values must '\\\n",
    "                            'sum to 1.0' in str(weight_array_sum.exception))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def test_false_alpha(self):\n",
    "        def broken_alpha():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(adaptive_weights = 'ridge',alpha = -10)\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as alpha:\n",
    "            broken_alpha()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. The alpha needs to be '\\\n",
    "                            'positive for ridge regressions.' in str(alpha.exception))\n",
    "        \n",
    "    def test_false_adaptive_weights(self):\n",
    "        def broken_adaptive_weights():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            model = matching.FLAME(adaptive_weights = 'safdsaf')\n",
    "            model.fit(holdout_data=df)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as adaptive_weights:\n",
    "            broken_adaptive_weights()\n",
    "            \n",
    "        self.assertTrue(\"Invalid input error. The acceptable values for \"\\\n",
    "                            \"the adaptive_weights parameter are 'ridge', \"\\\n",
    "                            \"'decisiontree', 'decisiontreeCV', or 'ridgeCV'. Additionally, \"\\\n",
    "                            \"adaptive-weights may be 'False' along \"\\\n",
    "                            \"with a weight array\" in str(adaptive_weights.exception))\n",
    "        \n",
    "    def test_false_data_len(self):\n",
    "        def broken_data_len():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000,\n",
    "                                                  num_cov=7, min_val=0,\n",
    "                                                  max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as data_len:\n",
    "            broken_data_len()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. The holdout and main '\\\n",
    "                            'dataset must have the same number of columns' in str(data_len.exception))\n",
    "    \n",
    "    def test_false_column_match(self):\n",
    "        def broken_column_match():\n",
    "            df, true_TE = generate_uniform_given_importance()\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "            set_ = holdout.columns\n",
    "            set_ = list(set_)\n",
    "            set_[0] = 'dasfadf'\n",
    "            holdout.columns  = set_\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as column_match:\n",
    "            broken_column_match()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. The holdout and main '\\\n",
    "                            'dataset must have the same columns' in str(column_match.exception))\n",
    "    def test_false_C(self):\n",
    "        def broken_C():\n",
    "            df, true_TE = generate_uniform_given_importance()\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df,C = -1)\n",
    "\n",
    "        with self.assertRaises(Exception) as C:\n",
    "            broken_C()\n",
    "            \n",
    "        self.assertTrue('The C, or the hyperparameter to trade-off between'\\\n",
    "                           ' balancing factor and predictive error must be '\\\n",
    "                           ' nonnegative. 'in str(C.exception))\n",
    "    def test_false_missing_data_replace(self):\n",
    "        def broken_missing_data_replace():\n",
    "                df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                                              num_cov=7, min_val=0,\n",
    "                                                              max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                holdout, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100,\n",
    "                                                      num_cov=7, min_val=0,\n",
    "                                                          max_val=3, covar_importance=[4,3,2,1,0,0,0])\n",
    "                covar_importance = np.array([4,3,2,1,0,0,0])\n",
    "                weight_array = covar_importance/covar_importance.sum()\n",
    "                model = matching.FLAME(missing_data_replace = 2, adaptive_weights =False)\n",
    "                model.fit(holdout_data=holdout,weight_array = list(weight_array))\n",
    "                output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as missing_data_replace:\n",
    "            broken_missing_data_replace()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. We do not support missing data '\\\n",
    "                        'handing in the fixed weights version of algorithms'in str(missing_data_replace.exception))\n",
    "        \n",
    "    def test_false_treatment_column_name(self):\n",
    "        def broken_treatment_column_name():\n",
    "            df, true_TE = generate_uniform_given_importance()\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout,treatment_column_name =  \"sadfdag\")\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as treatment_column_name:\n",
    "            broken_treatment_column_name()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. Treatment column name does not'\\\n",
    "                        ' exist' in str(treatment_column_name.exception))\n",
    "\n",
    "    def test_false_outcome_column_name(self):\n",
    "        def broken_outcome_column_name():\n",
    "            df, true_TE = generate_uniform_given_importance()\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout,outcome_column_name =  \"sadfdag\")\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as outcome_column_name:\n",
    "            broken_outcome_column_name()\n",
    "            \n",
    "        self.assertTrue('Invalid input error. Outcome column name does not'\\\n",
    "                        ' exist' in str(outcome_column_name.exception))\n",
    "        \n",
    "    def test_false_treatment_column_name_value(self):\n",
    "        def broken_treatment_column_name_value():\n",
    "            df, true_TE = generate_uniform_given_importance()\n",
    "            holdout, true_TE = generate_uniform_given_importance()\n",
    "            df.loc[0,'treated'] = 4\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as treatment_column_name_value:\n",
    "            broken_treatment_column_name_value()\n",
    "        self.assertTrue('Invalid input error. All rows in the treatment '\\\n",
    "                        'column must have either a 0 or a 1 value.' in str(treatment_column_name_value.exception))\n",
    "        \n",
    "\n",
    "#     def test_false_weight_array_order(self):\n",
    "#         def broken_weight_array_sum():\n",
    "#             df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "#             model = matching.FLAME(adaptive_weights = False)\n",
    "#             model.fit(holdout_data=df, weight_array = [1,1,1,1])\n",
    "#             output = model.predict(df)\n",
    "\n",
    "#         with self.assertRaises(Exception) as weight_array_sum:\n",
    "#             broken_weight_array_sum()\n",
    "            \n",
    "#         self.assertTrue('Invalid input error. Weight array values must '\\\n",
    "#                             'sum to 1.0' in str(weight_array_sum.exception))\n",
    "        \n",
    "    def test_false_data_type(self):\n",
    "        def broken_data_type():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            holdout = df.copy()\n",
    "            df.iloc[0,0] = 's'\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as _data_type:\n",
    "            broken_data_type()\n",
    "\n",
    "        self.assertTrue('Invalid input error. Ensure all inputs asides from '\\\n",
    "                        'the outcome column are integers, and if missing' \\\n",
    "                        ' values exist, ensure they are handled.' in str(_data_type.exception))\n",
    "    def test_false_holdout_type(self):\n",
    "        def broken_holdout_type():\n",
    "            df, true_TE = generate_uniform_given_importance(num_control=100, num_treated=100)\n",
    "            holdout = df.copy()\n",
    "            holdout.iloc[0,0] = 's'\n",
    "            model = matching.FLAME()\n",
    "            model.fit(holdout_data=holdout)\n",
    "            output = model.predict(df)\n",
    "\n",
    "        with self.assertRaises(Exception) as holdout_type:\n",
    "            broken_holdout_type()\n",
    "\n",
    "        self.assertTrue('Invalid input error. Ensure all inputs asides from '\\\n",
    "                                'the outcome column are integers, and if missing' \\\n",
    "                                ' values exist, ensure they are handled.' in str(holdout_type.exception))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>outcome</th>\n",
       "      <th>treated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  outcome  treated\n",
       "0     2  0  0  2       19        1\n",
       "1     1  0  1  2       17        1\n",
       "2     1  1  1  1       19        1\n",
       "3     0  1  2  0       14        1\n",
       "4     2  2  0  2       31        1\n",
       "...  .. .. .. ..      ...      ...\n",
       "1995  2  1  1  2       15        0\n",
       "1996  0  1  0  1        4        0\n",
       "1997  0  0  2  2        6        0\n",
       "1998  0  2  0  2        8        0\n",
       "1999  0  1  1  2        7        0\n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df,_ = generate_uniform_given_importance(num_control=1000, num_treated=1000)\n",
    "cols = tmp_df.columns\n",
    "tmp_df[cols] = tmp_df[cols].astype('int64')\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = Test_exceptions()\n",
    "# t.test_miss_data_F()\n",
    "t.test_false_holdout_type()\n",
    "t.test_false_data_type()\n",
    "# t.test_false_verbose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is missing data in this dataset. The default missing data handling is being done, so we are running MICE on 10 imputed holdout datasets\n",
      "Warning: You have opted to run MICE on the matching dataset. This is slow, and not recommended. We recommend that instead, you run the algorithm and skip matching on missing data points, with the parameter missing_data_replace=2.\n",
      "2000 units matched. We finished with no more units to match\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DAME' object has no attribute 'units_per_group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-47bb1324d99a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcheck_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-3a03158bb92d>\u001b[0m in \u001b[0;36mcheck_statistics\u001b[0;34m(model, unit_id)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munit_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mATE_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mATE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mATT_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mATT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mMG_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munit_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github/ALex/DAME-FLAME-Python-Package/dame_flame/utils/post_processing.py\u001b[0m in \u001b[0;36mATE\u001b[0;34m(matching_object, mice_iter)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mnum_groups_per_unit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatching_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups_per_unit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0marray_MGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatching_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits_per_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmice_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mnum_groups_per_unit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatching_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups_per_unit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmice_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DAME' object has no attribute 'units_per_group'"
     ]
    }
   ],
   "source": [
    "for missing_holdout_replace in [0]:\n",
    "    for missing_data_replace in [3]:\n",
    "        #Test missig data handling\n",
    "        df, true_TE = generate_uniform_given_importance(num_control=1000, num_treated=1000)\n",
    "        #Create missing df\n",
    "        m,n = df.shape\n",
    "        for i in range(int(m/10)):\n",
    "            for j in [0,int(n/2)]:\n",
    "                df.iloc[i,j] = np.nan\n",
    "        holdout = df.copy()\n",
    "        model = matching.DAME(repeats = False,missing_holdout_replace = missing_holdout_replace,missing_data_replace=missing_data_replace )\n",
    "        model.fit(holdout_data=holdout)\n",
    "        output = model.predict(df)\n",
    "        check_statistics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
